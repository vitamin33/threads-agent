# .github/workflows/dev-ci.yml
name: dev-ci

on:
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      force_build:
        description: 'Force build all images (ignore cache)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
#   #dev branches keep feedback loop tight
#   push:
#     branches: [cra-*]

jobs:
  test:
    name: py${{ matrix.python }} • k3d
    runs-on: ubuntu-22.04
    timeout-minutes: 15 # fail-fast guard
    strategy:
      fail-fast: false # let both versions run
      matrix:
        python: ["3.12"]

    steps:
      # ————————————————————————————————
      # 0.  Checkout code
      # ————————————————————————————————
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # for proper cache keys

      # ————————————————————————————————
      # 1.  Login to GitHub Container Registry
      # ————————————————————————————————
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # ————————————————————————————————
      # 2.  Spin local k3d cluster ⬅️ must be *before* image import
      # ————————————————————————————————
      - name: Create k3d cluster
        uses: AbsaOSS/k3d-action@v2
        with:
          cluster-name: dev # => kubectl context "k3d-dev"
          # args: --wait                    # uncomment if you want hard blocking

      # ————————————————————————————————
      # 3.  Pull or build images
      # ————————————————————————————————
      - name: Pull or build images
        run: |
          # Try to pull from GHCR first, build only if not found or force_build is true
          SERVICES="orchestrator celery_worker persona_runtime fake_threads viral_engine revenue"
          FORCE_BUILD="${{ github.event.inputs.force_build || 'false' }}"

          # Determine image tag based on event type
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            IMAGE_TAG="pr-${{ github.event.pull_request.number }}"
          else
            IMAGE_TAG="main"
          fi

          for svc in $SERVICES; do
            IMAGE_NAME="ghcr.io/${{ github.repository }}/${svc}:${IMAGE_TAG}"
            LOCAL_NAME="${svc//_/-}:local"

            if [ "$FORCE_BUILD" = "true" ]; then
              echo "🔨 Force building $svc..."
              docker build -f services/${svc}/Dockerfile -t "$LOCAL_NAME" .
            else
              echo "Attempting to pull $IMAGE_NAME..."
              if docker pull "$IMAGE_NAME" 2>/dev/null; then
                echo "✅ Found pre-built image for $svc"
                docker tag "$IMAGE_NAME" "$LOCAL_NAME"
              else
                echo "⚠️  No pre-built image found for $svc, building locally..."
                docker build -f services/${svc}/Dockerfile -t "$LOCAL_NAME" .
              fi
            fi
          done

          # Always pull these third-party images
          docker pull bitnami/postgresql:16
          docker pull rabbitmq:3.13-management-alpine
          docker pull qdrant/qdrant:v1.9.4

          # Import all images to k3d
          k3d image import \
            orchestrator:local \
            celery-worker:local \
            persona-runtime:local \
            fake-threads:local \
            viral-engine:local \
            revenue:local \
            qdrant/qdrant:v1.9.4 \
            -c dev

      # ————————————————————————————————
      # 4.  Helm install with CI values
      # ————————————————————————————————
      - name: Helm upgrade (dev cluster)
        id: helm
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MOCK: "1"
        run: |
          helm upgrade --install threads ./chart \
            -f chart/values-ci.yaml \
            --set openai.apiKey="$OPENAI_API_KEY" \
            --wait --timeout 300s --debug

      # ─── If Helm failed, dump cluster state ──────────────────────────────
      - name: Dump pod list + events if Helm failed
        if: steps.helm.outcome == 'failure'
        run: |
          echo "❌ Helm release did not become ready. Dumping diagnostics …"
          kubectl get pods -A -o wide
          kubectl get events --sort-by='.lastTimestamp' -A | tail -n 40
          # Show logs of pods stuck in Pending / CrashLoop
          for p in $(kubectl get pods --no-headers | awk '$3!="Running"{print $1}'); do
            echo "──── logs: $p ────"
            kubectl logs "$p" --tail=100 || true
          done
          # Fail the step explicitly so the job still turns red
          exit 1
      - name: Wait for core pods
        run: |
          # deployments
          kubectl rollout status deploy/orchestrator     --timeout=120s
          kubectl rollout status deploy/celery-worker    --timeout=120s
          kubectl rollout status deploy/fake-threads     --timeout=120s
          kubectl rollout status deploy/persona-runtime  --timeout=120s
          kubectl rollout status sts/qdrant              --timeout=120s

      # ————————————————————————————————
      # 4.  Set-up Python & cache venv
      # ————————————————————————————————
      - name: Set up Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r services/orchestrator/requirements.txt
          pip install -r services/celery_worker/requirements.txt
          pip install -r services/persona_runtime/requirements.txt
          pip install -r services/fake_threads/requirements.txt
          pip install -r services/viral_engine/requirements.txt
          pip install -r tests/requirements.txt

      # ————————————————————————————————
      # 5.  Run unit + e2e suites
      # ————————————————————————————————
      - name: pytest (unit + e2e)
        id: tests
        run: |
          # ➊ start port-forwards in the background
          kubectl port-forward svc/orchestrator 8080:8080   & PF_ORCH=$!
          kubectl port-forward svc/fake-threads 9009:9009   & PF_THREADS=$!
          kubectl port-forward svc/qdrant 6333:6333         & PF_QDRANT=$!
          kubectl port-forward svc/postgres 15432:5432      & PF_POSTGRES=$!
          # give the tunnel a moment
          sleep 5

          # ➋ run the test suite (tests already hit localhost:8080)
          export PYTHONPATH=$PWD:$PYTHONPATH
          pytest -q

          # ➌ tidy up
          kill $PF_ORCH $PF_THREADS $PF_QDRANT $PF_POSTGRES

      # ─── EXTRA: show Celery-worker logs if the tests failed ──────────────
      - name: Dump worker logs if pytest failed
        if: failure()
        run: |
          echo "⚠️  pytest failed, printing celery-worker logs…"
          kubectl logs deploy/celery-worker --tail=150 || true

      # ————————————————————————————————
      # 6.  Render Mermaid diagram
      # ————————————————————————————————
      - name: Render infra diagram
        run: |
          npm install -g @mermaid-js/mermaid-cli@^10
          mmdc -i docs/infra.mmd -o docs/infra.svg

      # ————————————————————————————————
      # 7.  Upload infra.svg artifact
      # ————————————————————————————————
      - name: Upload infra diagram
        uses: actions/upload-artifact@v4
        with:
          name: infra-svg
          path: docs/infra.svg

# .github/workflows/dev-ci.yml
name: dev-ci

on:
  pull_request:
    branches: [main]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.gitignore'
      - 'LICENSE'
      - '.env.example'
  workflow_dispatch:
    inputs:
      force_build:
        description: 'Force build all images (ignore cache)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

permissions:
  contents: read
  pull-requests: read
#   #dev branches keep feedback loop tight
#   push:
#     branches: [cra-*]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    name: py${{ matrix.python }} • k3d
    runs-on: ubuntu-22.04
    timeout-minutes: 15 # fail-fast guard
    strategy:
      fail-fast: false # let both versions run
      matrix:
        python: ["3.12"]

    steps:
      # ————————————————————————————————
      # 0.  Checkout code
      # ————————————————————————————————
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # for proper cache keys

      # ————————————————————————————————
      # 0.25  Detect changed files
      # ————————————————————————————————
      - name: Detect changed files
        id: changes
        uses: dorny/paths-filter@v3
        with:
          token: ${{ github.token }}
          filters: |
            python:
              - '**/*.py'
              - '**/requirements*.txt'
              - 'pytest.ini'
              - 'pyproject.toml'
              - 'mypy.ini'
            orchestrator:
              - 'services/orchestrator/**'
              - 'services/common/**'
            celery_worker:
              - 'services/celery_worker/**'
              - 'services/common/**'
            persona_runtime:
              - 'services/persona_runtime/**'
              - 'services/common/**'
            fake_threads:
              - 'services/fake_threads/**'
              - 'services/common/**'
            viral_engine:
              - 'services/viral_engine/**'
              - 'services/common/**'
            revenue:
              - 'services/revenue/**'
              - 'services/common/**'
            tests:
              - 'tests/**'
            e2e_required:
              - 'chart/**'
              - '**/Dockerfile'
              - 'scripts/**'

      # ————————————————————————————————
      # 0.5  Cache test results
      # ————————————————————————————————
      - name: Cache test results
        uses: actions/cache@v4
        with:
          path: |
            .pytest_cache
            .mypy_cache
            htmlcov
            .coverage
          key: test-results-${{ runner.os }}-py${{ matrix.python }}-${{ hashFiles('**/*.py', '**/requirements*.txt', 'mypy.ini', 'pytest.ini', 'pyproject.toml') }}
          restore-keys: |
            test-results-${{ runner.os }}-py${{ matrix.python }}-
            test-results-${{ runner.os }}-

      # ————————————————————————————————
      # 1.  Login to GitHub Container Registry
      # ————————————————————————————————
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # ————————————————————————————————
      # 2.  Spin local k3d cluster (only if needed)
      # ————————————————————————————————
      - name: Create k3d cluster
        if: steps.changes.outputs.e2e_required == 'true'
        uses: AbsaOSS/k3d-action@v2
        with:
          cluster-name: dev # => kubectl context "k3d-dev"
          # args: --wait                    # uncomment if you want hard blocking

      # ————————————————————————————————
      # 3.  Pull or build images (only if needed)
      # ————————————————————————————————
      - name: Pull or build images
        if: steps.changes.outputs.e2e_required == 'true'
        run: |
          # Try to pull from GHCR first, build only if not found or force_build is true
          SERVICES="orchestrator celery_worker persona_runtime fake_threads viral_engine revenue"
          FORCE_BUILD="${{ github.event.inputs.force_build || 'false' }}"

          # Determine image tag based on event type
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            IMAGE_TAG="pr-${{ github.event.pull_request.number }}"
          else
            IMAGE_TAG="main"
          fi

          for svc in $SERVICES; do
            IMAGE_NAME="ghcr.io/${{ github.repository }}/${svc}:${IMAGE_TAG}"
            LOCAL_NAME="${svc//_/-}:local"

            if [ "$FORCE_BUILD" = "true" ]; then
              echo "🔨 Force building $svc..."
              docker build -f services/${svc}/Dockerfile -t "$LOCAL_NAME" .
            else
              echo "Attempting to pull $IMAGE_NAME..."
              if docker pull "$IMAGE_NAME" 2>/dev/null; then
                echo "✅ Found pre-built image for $svc"
                docker tag "$IMAGE_NAME" "$LOCAL_NAME"
              else
                echo "⚠️  No pre-built image found for $svc, building locally..."
                docker build -f services/${svc}/Dockerfile -t "$LOCAL_NAME" .
              fi
            fi
          done

          # Always pull these third-party images
          docker pull bitnami/postgresql:16
          docker pull rabbitmq:3.13-management-alpine
          docker pull qdrant/qdrant:v1.9.4

          # Import all images to k3d
          k3d image import \
            orchestrator:local \
            celery-worker:local \
            persona-runtime:local \
            fake-threads:local \
            viral-engine:local \
            revenue:local \
            qdrant/qdrant:v1.9.4 \
            -c dev

      # ————————————————————————————————
      # 4.  Helm install with CI values (only if needed)
      # ————————————————————————————————
      - name: Helm upgrade (dev cluster)
        if: steps.changes.outputs.e2e_required == 'true'
        id: helm
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MOCK: "1"
        run: |
          helm upgrade --install threads ./chart \
            -f chart/values-ci.yaml \
            --set openai.apiKey="$OPENAI_API_KEY" \
            --wait --timeout 300s --debug \
            --atomic

      # ─── If Helm failed, dump cluster state ──────────────────────────────
      - name: Dump pod list + events if Helm failed
        if: steps.helm.outcome == 'failure' && steps.changes.outputs.e2e_required == 'true'
        run: |
          echo "❌ Helm release did not become ready. Dumping diagnostics …"
          kubectl get pods -A -o wide
          kubectl get events --sort-by='.lastTimestamp' -A | tail -n 40
          # Show logs of pods stuck in Pending / CrashLoop
          for p in $(kubectl get pods --no-headers | awk '$3!="Running"{print $1}'); do
            echo "──── logs: $p ────"
            kubectl logs "$p" --tail=100 || true
          done
          # Fail the step explicitly so the job still turns red
          exit 1
      - name: Wait for core pods (parallel)
        if: steps.changes.outputs.e2e_required == 'true'
        run: |
          echo "⏳ Waiting for all pods to be ready (in parallel)..."

          # Start all checks in parallel
          kubectl rollout status deploy/orchestrator     --timeout=120s &
          kubectl rollout status deploy/celery-worker    --timeout=120s &
          kubectl rollout status deploy/fake-threads     --timeout=120s &
          kubectl rollout status deploy/persona-runtime  --timeout=120s &
          kubectl rollout status sts/qdrant              --timeout=120s &

          # Wait for all background jobs to complete
          JOBS=$(jobs -p)
          for job in $JOBS; do
            wait $job || exit 1
          done

          echo "✅ All pods are ready!"

      # ————————————————————————————————
      # 4.  Set-up Python & cache venv
      # ————————————————————————————————
      - name: Set up Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Generate requirements hash
        id: requirements-hash
        run: |
          # Combine all requirements for a stable cache key
          cat services/*/requirements.txt tests/requirements.txt | sort | uniq > .all-requirements.txt
          echo "hash=${{ hashFiles('.all-requirements.txt') }}" >> $GITHUB_OUTPUT

      - name: Cache pip and venv
        uses: actions/cache@v4
        id: python-cache
        with:
          path: |
            ~/.cache/pip
            .venv
          key: ${{ runner.os }}-python-${{ matrix.python }}-${{ hashFiles('**/requirements*.txt', 'pyproject.toml', 'setup.py', 'setup.cfg') }}
          restore-keys: |
            ${{ runner.os }}-python-${{ matrix.python }}-
            ${{ runner.os }}-python-

      - name: Setup virtual environment
        run: |
          python -m venv .venv
          echo "$PWD/.venv/bin" >> $GITHUB_PATH

      - name: Install deps (with cache awareness)
        run: |
          # Upgrade pip first
          python -m pip install -U pip wheel setuptools

          # Check if we have a cache hit
          if [ "${{ steps.python-cache.outputs.cache-hit }}" != "true" ]; then
            echo "📦 No cache hit, installing all dependencies..."
            pip install -r services/orchestrator/requirements.txt
            pip install -r services/celery_worker/requirements.txt
            pip install -r services/persona_runtime/requirements.txt
            pip install -r services/fake_threads/requirements.txt
            pip install -r services/viral_engine/requirements.txt
            pip install -r tests/requirements.txt
          else
            echo "✅ Cache hit! Checking for any missing packages..."
            # Quick install to catch any missing dependencies
            pip install --no-deps -r services/orchestrator/requirements.txt
            pip install --no-deps -r services/celery_worker/requirements.txt
            pip install --no-deps -r services/persona_runtime/requirements.txt
            pip install --no-deps -r services/fake_threads/requirements.txt
            pip install --no-deps -r services/viral_engine/requirements.txt
            pip install --no-deps -r tests/requirements.txt
          fi

          # Show what's installed
          pip list

      # ————————————————————————————————
      # 5.  Run unit + e2e suites (smart selection)
      # ————————————————————————————————
      - name: pytest (unit + e2e) - parallel with smart selection
        id: tests
        run: |
          # Determine which tests to run based on changes
          PYTEST_ARGS="-q -p no:langsmith -n auto --maxprocesses=4 --dist loadscope --timeout=60"

          # If no Python files changed, skip tests entirely
          if [ "${{ steps.changes.outputs.python }}" != "true" ]; then
            echo "✅ No Python files changed, skipping tests"
            exit 0
          fi

          # Build test selection based on what changed
          TEST_PATHS=""

          # Service-specific tests
          if [ "${{ steps.changes.outputs.orchestrator }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS services/orchestrator/tests"
          fi
          if [ "${{ steps.changes.outputs.celery_worker }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS services/celery_worker/tests"
          fi
          if [ "${{ steps.changes.outputs.persona_runtime }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS services/persona_runtime/tests"
          fi
          if [ "${{ steps.changes.outputs.fake_threads }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS services/fake_threads/tests"
          fi
          if [ "${{ steps.changes.outputs.viral_engine }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS services/viral_engine/tests"
          fi
          if [ "${{ steps.changes.outputs.revenue }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS services/revenue/tests"
          fi

          # Always add unit tests if tests directory changed
          if [ "${{ steps.changes.outputs.tests }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS tests/unit"
          fi

          # Run e2e tests only if infrastructure changed
          if [ "${{ steps.changes.outputs.e2e_required }}" = "true" ]; then
            TEST_PATHS="$TEST_PATHS tests/e2e"
            RUN_E2E=true
          else
            # Skip e2e tests
            PYTEST_ARGS="$PYTEST_ARGS -m 'not e2e'"
            RUN_E2E=false
          fi

          # If no specific paths selected, run all tests (fallback)
          if [ -z "$TEST_PATHS" ]; then
            TEST_PATHS="."
          fi

          # Only start port-forwards if running e2e tests
          if [ "$RUN_E2E" = "true" ]; then
            # ➊ start port-forwards in the background
            kubectl port-forward svc/orchestrator 8080:8080   & PF_ORCH=$!
            kubectl port-forward svc/fake-threads 9009:9009   & PF_THREADS=$!
            kubectl port-forward svc/qdrant 6333:6333         & PF_QDRANT=$!
            kubectl port-forward svc/postgres 15432:5432      & PF_POSTGRES=$!
            # give the tunnel a moment
            sleep 5
          fi

          # ➋ run the test suite with parallel execution
          export PYTHONPATH=$PWD:$PYTHONPATH
          # Disable langsmith to avoid pydantic v1 compatibility issues
          export LANGCHAIN_TRACING_V2=false
          export LANGSMITH_TRACING=false

          echo "🧪 Running tests for: $TEST_PATHS"
          pytest $PYTEST_ARGS $TEST_PATHS -x  # -x stops on first failure

          # ➌ tidy up port-forwards if started
          if [ "$RUN_E2E" = "true" ]; then
            kill $PF_ORCH $PF_THREADS $PF_QDRANT $PF_POSTGRES || true
          fi

      # ─── EXTRA: show Celery-worker logs if the tests failed ──────────────
      - name: Dump worker logs if pytest failed
        if: failure()
        run: |
          echo "⚠️  pytest failed, printing celery-worker logs…"
          kubectl logs deploy/celery-worker --tail=150 || true

      # ————————————————————————————————
      # 6.  Render Mermaid diagram
      # ————————————————————————————————
      - name: Render infra diagram
        run: |
          npm install -g @mermaid-js/mermaid-cli@^10
          mmdc -i docs/infra.mmd -o docs/infra.svg

      # ————————————————————————————————
      # 7.  Upload infra.svg artifact
      # ————————————————————————————————
      - name: Upload infra diagram
        uses: actions/upload-artifact@v4
        with:
          name: infra-svg
          path: docs/infra.svg

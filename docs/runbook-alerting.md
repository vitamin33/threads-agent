# AlertManager Runbook - Threads-Agent Stack

## Overview

This runbook provides operational guidance for responding to alerts generated by the Threads-Agent Stack AlertManager system. All alerts are categorized by severity and routed to appropriate channels for timely response.

## Alert Categories

### Critical Alerts (PagerDuty) üö®
- **Channel**: PagerDuty (immediate escalation)
- **Response Time**: < 5 minutes
- **Escalation**: Automatic after 15 minutes if not acknowledged

### Warning Alerts (Slack) ‚ö†Ô∏è
- **Channel**: Slack #alerts-warnings
- **Response Time**: < 30 minutes
- **Escalation**: Manual escalation to email after 2 hours

### Business Alerts (Email) üìà
- **Channel**: Email to business stakeholders
- **Response Time**: < 2 hours
- **Escalation**: Daily digest if unresolved

### Infrastructure Alerts (Hybrid) üèóÔ∏è
- **Channel**: Slack + Email
- **Response Time**: < 1 hour
- **Escalation**: PagerDuty if multiple infrastructure components fail

## Alert Response Procedures

### ServiceDown
**Severity**: Critical  
**Description**: Service instance is down for >1 minute  
**Response**:
1. Check service status: `kubectl get pods -l app=<service>`
2. Review logs: `kubectl logs deployment/<service> --tail=100`
3. Check resource constraints: `kubectl describe pod <pod-name>`
4. Restart if necessary: `kubectl rollout restart deployment/<service>`
5. Verify recovery: Check service metrics in Grafana

### HighErrorRate
**Severity**: Critical  
**Description**: Service error rate >5% for 5 minutes  
**Response**:
1. Identify error source: Check /metrics endpoint
2. Review application logs for error patterns
3. Check database connectivity: `kubectl exec -it deployment/postgres -- psql -U postgres -c "SELECT 1"`
4. Verify external dependencies (OpenAI API, RabbitMQ)
5. Roll back recent deployments if errors started after deployment

### DatabaseConnectionFailure
**Severity**: Critical  
**Description**: No active database connections detected  
**Response**:
1. Check PostgreSQL pod: `kubectl get pods -l app=postgres`
2. Test connection: `kubectl exec -it deployment/orchestrator -- python -c "import psycopg2; psycopg2.connect('postgresql://postgres:pass@postgres:5432/postgres')"`
3. Check database logs: `kubectl logs deployment/postgres`
4. Verify database resources and restart if needed
5. Check connection pool configuration in services

### CeleryQueueDepthHigh
**Severity**: Critical  
**Description**: Celery queue >1000 messages for 2+ minutes  
**Response**:
1. Check queue status: Access RabbitMQ management UI
2. Scale Celery workers: `kubectl scale deployment celery-worker --replicas=3`
3. Check worker health: `kubectl logs deployment/celery-worker`
4. Identify stuck tasks: Review Celery worker logs for exceptions
5. Clear problematic tasks if necessary

### HighLatency
**Severity**: Warning  
**Description**: p95 latency >2s for 10 minutes  
**Response**:
1. Identify slow endpoints: Check Grafana performance dashboard
2. Review database query performance: Check slow query logs
3. Check resource utilization: CPU/Memory metrics
4. Scale services if needed: `kubectl scale deployment <service> --replicas=2`
5. Optimize slow queries or endpoints

### HighTokenCost
**Severity**: Warning  
**Description**: OpenAI costs >$5/hour for 15 minutes  
**Response**:
1. Check token usage by model: Review Prometheus metrics
2. Identify high-usage personas: Check per-persona cost metrics
3. Review recent content generation volume
4. Implement rate limiting if necessary
5. Consider switching to cheaper models for non-critical tasks

### LowEngagementRate
**Severity**: Warning (Business)  
**Description**: Engagement rate <4% for 30 minutes  
**Response**:
1. Review recent posts quality: Check content quality metrics
2. Analyze persona performance: Compare against historical data
3. Check content generation pipeline: Verify LLM model performance
4. Review trending topics: Ensure content relevance
5. Consider persona strategy adjustment

### HighCostPerFollow
**Severity**: Warning (Business)  
**Description**: Cost per follow >$0.02 for 30 minutes  
**Response**:
1. Calculate ROI: Review revenue per follower
2. Analyze cost drivers: Token usage vs. follower acquisition
3. Optimize content strategy: Focus on high-engagement content
4. Review targeting: Ensure content reaches right audience
5. Consider budget reallocation across personas

## Escalation Procedures

### Level 1: Automatic Response
- AlertManager sends notifications to configured channels
- On-call engineer receives PagerDuty alert for critical issues
- Slack/Email notifications for warnings and business alerts

### Level 2: Manual Escalation (1 hour)
If alerts persist or multiple services affected:
1. Create incident in Linear: [Link to incident template]
2. Start incident response chat channel
3. Engage additional team members
4. Update status page if customer-facing

### Level 3: Executive Escalation (4 hours)
For prolonged outages affecting business metrics:
1. Notify leadership team
2. Prepare status updates
3. Consider customer communication
4. Plan post-incident review

## Troubleshooting Commands

### Quick Health Checks
```bash
# Service status
kubectl get pods -l app=orchestrator
kubectl get pods -l app=celery-worker
kubectl get pods -l app=persona-runtime

# Resource usage
kubectl top pods

# Recent events
kubectl get events --sort-by='.lastTimestamp' | tail -20
```

### Database Health
```bash
# Connection test
kubectl exec -it deployment/orchestrator -- python -c "
import psycopg2
try:
    conn = psycopg2.connect('postgresql://postgres:pass@postgres:5432/postgres')
    print('‚úÖ Database connection successful')
    conn.close()
except Exception as e:
    print(f'‚ùå Database connection failed: {e}')
"

# Database size
kubectl exec -it deployment/postgres -- psql -U postgres -c "
SELECT schemaname,tablename,pg_size_pretty(size) 
FROM (
  SELECT schemaname, tablename, pg_total_relation_size(schemaname||'.'||tablename) AS size
  FROM pg_tables WHERE schemaname = 'public'
) AS table_sizes ORDER BY size DESC;
"
```

### Queue Health
```bash
# RabbitMQ status
kubectl port-forward svc/rabbitmq 15672:15672
# Access http://localhost:15672 (guest/guest)

# Celery worker status
kubectl exec -it deployment/celery-worker -- celery -A tasks status
```

### Performance Analysis
```bash
# Application logs with timing
kubectl logs deployment/orchestrator | grep -E "(latency|duration|slow)"

# Resource usage over time
kubectl top pods --use-protocol-buffers --sort-by=cpu
kubectl top pods --use-protocol-buffers --sort-by=memory
```

## Monitoring Dashboards

- **Business KPIs**: http://localhost:3000/d/business-kpis
- **Technical Metrics**: http://localhost:3000/d/technical-metrics
- **Infrastructure**: http://localhost:3000/d/infrastructure-overview
- **AlertManager**: http://localhost:9093
- **Prometheus**: http://localhost:9090

## Contact Information

- **On-call Engineer**: PagerDuty escalation
- **Engineering Team**: Slack #engineering
- **Operations**: ops@threads-agent.com
- **Business Stakeholders**: business@threads-agent.com

## Post-Incident Actions

1. **Immediate (within 1 hour)**:
   - Ensure full service recovery
   - Document incident timeline
   - Update monitoring if gaps identified

2. **Short-term (within 24 hours)**:
   - Conduct post-incident review
   - Identify root cause
   - Create Linear issues for improvements

3. **Long-term (within 1 week)**:
   - Implement preventive measures
   - Update runbooks with learnings
   - Consider architectural improvements

## Alert Suppression

For planned maintenance:
```bash
# Silence alerts for 2 hours
curl -X POST http://localhost:9093/api/v1/silences -d '{
  "matchers": [{"name": "service", "value": "orchestrator"}],
  "startsAt": "'$(date -Iseconds)'",
  "endsAt": "'$(date -d '+2 hours' -Iseconds)'",
  "createdBy": "maintenance-user",
  "comment": "Planned maintenance window"
}'
```

## Metrics to Monitor During Incidents

- **Service Health**: Up/down status, response time
- **Error Rates**: 4xx/5xx HTTP responses, exception rates
- **Resource Usage**: CPU, memory, disk space
- **Business Impact**: Content generation rate, engagement metrics
- **External Dependencies**: OpenAI API status, database performance

---

**Last Updated**: 2025-07-22  
**Next Review**: Monthly  
**Document Owner**: SRE Team
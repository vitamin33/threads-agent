# =========================================
#  Threads-Agent â€“ Dev helper recipes
# =========================================
set dotenv-load

# ---------- K8s Dev Platform ----------
bootstrap:          # spin local k3d (legacy single cluster)
    ./scripts/dev-up.sh

# Multi-developer cluster management
bootstrap-multi ARGS="": # create unique k3d cluster per developer/repo
    ./scripts/dev-up-multi.sh {{ARGS}}

cluster CMD="list" ARGS="": # manage multiple k3d clusters
    ./scripts/cluster-manager.sh {{CMD}} {{ARGS}}

cluster-list: # list all available clusters
    @./scripts/cluster-manager.sh list

cluster-switch NAME: # switch to a different cluster
    @./scripts/cluster-manager.sh switch {{NAME}}

cluster-current: # show current active cluster
    @./scripts/cluster-manager.sh current

cluster-delete NAME: # delete a specific cluster
    @./scripts/cluster-manager.sh delete {{NAME}}


# -----------------------------------------------------------------
# single helper that builds + pre-pulls all images, then loads
# everything (including Postgres & RabbitMQ) into the k3d cluster
# -----------------------------------------------------------------
images CLUSTER="":
	@echo "ðŸ³  building dev images â€¦"

	for svc in orchestrator celery_worker persona_runtime fake_threads viral_engine threads_adaptor; do \
		docker build -f services/${svc}/Dockerfile -t ${svc//_/-}:local .; \
	done

	docker pull bitnami/postgresql:16
	docker pull rabbitmq:3.13-management-alpine

	# ---------- Qdrant ----------
	docker pull qdrant/qdrant:v1.9.4
	
	# Import to current cluster
	@cluster_name=$$(kubectl config current-context 2>/dev/null | sed 's/^k3d-//' || echo "dev"); \
	echo "ðŸ“¦ Importing images to cluster: $$cluster_name"; \
	k3d image import qdrant/qdrant:v1.9.4 -c $$cluster_name || true; \
	k3d image import bitnami/postgresql:16 -c $$cluster_name || true; \
	k3d image import rabbitmq:3.13-management-alpine -c $$cluster_name || true; \
	for img in orchestrator celery-worker persona-runtime fake-threads viral-engine threads-adaptor; do \
		k3d image import $${img}:local -c $$cluster_name || true; \
	done; \
	echo "ðŸ”  images inside k3d nodes:"; \
	docker exec k3d-$$cluster_name-agent-0 crictl images | grep -E "orchestrator|celery|persona|fake|viral|threads" || true

deploy-dev TIMEOUT="360s":
	@bash -ceu 'extra=""; [ -f chart/values-dev.local.yaml ] && extra="-f chart/values-dev.local.yaml"; \
	            helm upgrade --install threads ./chart -f chart/values-dev.yaml $extra \
	            --wait --timeout {{TIMEOUT}}'

k3d-stop-all:
	k3d cluster stop --all

k3d-nuke-all:
	k3d cluster delete --all

docker-cache-clear:
    @echo "ðŸ§¹  pruning buildx cache â€¦"
    docker builder prune -af

# full reset: cluster + cache
reset-hard:
    just k3d-nuke-all
    just docker-cache-clear

# ---------- Local e2e run ----------
e2e-prepare:          # full e2e setup: bootstrap + images + deploy + test
    @echo "ðŸš€  setting up complete e2e environment..."
    just bootstrap
    just images  
    just deploy-dev
    @echo "â³  waiting for services to be ready..."
    kubectl wait --for=condition=ready pod -l app=postgres --timeout=300s
    kubectl wait --for=condition=ready pod -l app=orchestrator --timeout=300s
    @echo "âœ…  e2e environment ready!"

e2e:
    @echo "ðŸ§ª  running e2e tests (with automatic service checks)..."
    PYTHONPATH=$PWD:${PYTHONPATH:-} pytest -s -m e2e

# ---------- Unit-only test run ----------
unit:
    PYTHONPATH=$PWD:${PYTHONPATH:-} pytest -q -m "not e2e"

logs:
    kubectl logs -l app=orchestrator -f --tail=100

logs-celery:
	kubectl logs -f deploy/celery-worker

test-watch SERVICE="":
	@echo "ðŸ”  watching testsâ€¦"
	@if [ "$(SERVICE)" != "" ]; then \
	    pt="services/$(SERVICE)"; \
	else \
	    pt="."; \
	fi; \
	pytest $$pt --maxfail=1 -q -f

scaffold SERVICE:
    mkdir -p services/{{SERVICE}}
    cp -r templates/service-template/* services/{{SERVICE}}/

    # replace in main.py
    sed -i '' "s/TEMPLATE_NAME/{{SERVICE}}/g" services/{{SERVICE}}/main.py

    # replace in test
    sed -i '' "s/TEMPLATE_NAME/{{SERVICE}}/g" services/{{SERVICE}}/tests/test_health.py

# ---------- Lint / Type-check / Tests ----------
lint:
	@echo "âš™  ruff (lint+format) â†’ isort â†’ black"
	@if [ -f .venv/bin/activate ]; then source .venv/bin/activate; fi && \
	ruff check --fix . && \
	ruff format . && \
	isort . --profile black --filter-files && \
	black .
	@./scripts/learning-system.sh track "just lint" 0 "1.0" "auto-format" 2>/dev/null || true

check: lint
	@echo "ðŸ”  mypy type-check"
	@if [ -f .venv/bin/activate ]; then source .venv/bin/activate; fi && mypy --config-file mypy.ini .
	@echo "ðŸ§ª  pytest suite"
	@if [ -f .venv/bin/activate ]; then source .venv/bin/activate; fi && PYTHONPATH=$PWD:${PYTHONPATH:-} pytest -q
	@echo "âœ…  all green"
	@./scripts/learning-system.sh track "just check" 0 "5.0" "full-check" 2>/dev/null || true

# ---------- Quality Gates ----------
quality-gate PHASE="pre-commit": # run quality gates system
	./scripts/quality-gates.sh {{PHASE}}

pre-commit-check: # lightweight pre-commit quality gates
	just lint
	./scripts/quality-gates.sh pre-commit

pre-commit-fix: # auto-fix issues then run pre-commit gates
	just lint
	@SKIP_FORMAT_CHECK=true SKIP_CLAUDE_REVIEW=true ./scripts/quality-gates.sh pre-commit

pre-deploy-check: # comprehensive pre-deploy quality gates  
	./scripts/quality-gates.sh pre-deploy

claude-review: # run Claude Code automated review
	./scripts/quality-gates.sh claude-review

security-check: # run security-focused quality checks
	./scripts/quality-gates.sh security

# ---------- Learning System ----------
learn ACTION="dashboard": # intelligent development learning and optimization
	./scripts/learning-system.sh {{ACTION}}

analyze-patterns: # analyze development patterns and suggest optimizations
	./scripts/learning-system.sh analyze && ./scripts/learning-system.sh suggest

learning-dashboard: # show interactive learning dashboard
	./scripts/learning-system.sh dashboard

learning-report: # generate comprehensive learning report
	./scripts/learning-system.sh report

benchmark-performance: # benchmark development operations
	./scripts/learning-system.sh benchmark

# ---------- Advanced Workflow Automation ----------
workflow ACTION="dashboard": # advanced workflow automation system
	./scripts/workflow-automation.sh {{ACTION}}

epic NAME DESCRIPTION="": # break down epic into features  
	./scripts/workflow-automation.sh epic "{{NAME}}" "{{DESCRIPTION}}"

feature ACTION ID: # manage feature lifecycle
	./scripts/workflow-automation.sh feature {{ACTION}} {{ID}}

orchestrate MODE="suggest": # intelligent development orchestration
	./scripts/workflow-automation.sh orchestrate {{MODE}}

workflow-dashboard: # show workflow automation dashboard
	./scripts/workflow-automation.sh dashboard

workflow-report: # generate workflow automation report
	./scripts/workflow-automation.sh report

# ---------- Solopreneur Morning Routine ----------
business-morning: # comprehensive morning briefing for solopreneurs
	@echo "ðŸŒ… Good Morning! Starting your business briefing..."
	@echo "==============================================="
	@echo ""
	@echo "ðŸ“Š CUSTOMER INTELLIGENCE OVERVIEW"
	@echo "-----------------------------------"
	@just ci-dashboard
	@echo ""
	@echo "ðŸ’° BUSINESS INTELLIGENCE SUMMARY" 
	@echo "--------------------------------"
	@just bi-dashboard
	@echo ""
	@echo "ðŸ§  DEVELOPMENT INSIGHTS"
	@echo "----------------------"
	@just learning-dashboard
	@echo ""
	@echo "ðŸ“ˆ DAILY ACTION ITEMS"
	@echo "--------------------"
	@just daily-insights
	@echo ""
	@echo "âœ¨ Morning briefing complete! Have a productive day! âœ¨"

business-evening: # enhanced customer-focused end-of-day review
	./scripts/customer-priority.sh enhanced-evening customer_centric

# Level 8A Customer Priority Commands
next-customer-priority FOCUS="all": # AI-powered next customer priority recommendation
	./scripts/customer-priority.sh next-priority {{FOCUS}}

code-for-retention FOCUS="engagement": # analyze retention-focused development opportunities
	./scripts/customer-priority.sh code-for-retention {{FOCUS}}

weekly-strategic-review FOCUS="comprehensive": # generate comprehensive weekly strategic review
	./scripts/customer-priority.sh weekly-strategic-review {{FOCUS}}

business-weekly: # enhanced weekly business review with strategic analysis
	./scripts/customer-priority.sh weekly-strategic-review comprehensive

# ---------- Customer Intelligence System ----------
ci ACTION="dashboard": # solopreneur customer intelligence system
	./scripts/customer-intelligence.sh {{ACTION}}

track-behavior USER ACTION PAGE="home" DURATION="0": # track user behavior event
	./scripts/customer-intelligence.sh track-behavior {{USER}} {{ACTION}} {{PAGE}} {{DURATION}}

pmf-survey USER DISAPPOINTED NPS BENEFIT IMPROVEMENT: # record PMF survey response
	./scripts/customer-intelligence.sh pmf-survey {{USER}} {{DISAPPOINTED}} {{NPS}} "{{BENEFIT}}" "{{IMPROVEMENT}}"

add-competitor NAME WEBSITE="" SOCIAL="" FOCUS="general": # add competitor to monitoring
	./scripts/customer-intelligence.sh add-competitor "{{NAME}}" "{{WEBSITE}}" "{{SOCIAL}}" {{FOCUS}}

competitor-update NAME TYPE DESCRIPTION IMPACT="medium" SOURCE="manual": # track competitor update
	./scripts/customer-intelligence.sh competitor-update "{{NAME}}" {{TYPE}} "{{DESCRIPTION}}" {{IMPACT}} {{SOURCE}}

ci-dashboard: # show customer intelligence dashboard
	./scripts/customer-intelligence.sh dashboard

ci-report TYPE="weekly": # generate customer intelligence report
	./scripts/customer-intelligence.sh report {{TYPE}}

daily-insights: # generate automated daily insights
	./scripts/customer-intelligence.sh daily-insights

setup-ci-automation: # configure automated CI tasks
	./scripts/customer-intelligence.sh setup-automation

# ---------- SearXNG Search Integration ----------
searxng-start: # start local SearXNG instance for search
	@echo "ðŸ” Starting SearXNG search engine..."
	@./scripts/setup-searxng.sh
	@cd .searxng && docker-compose up -d
	@echo "âœ… SearXNG available at http://localhost:8888"

searxng-stop: # stop SearXNG instance
	@cd .searxng && docker-compose down

searxng-logs: # view SearXNG logs
	@cd .searxng && docker-compose logs -f

searxng-test QUERY="AI trends 2025": # test SearXNG search
	@curl -s "http://localhost:8888/search?q={{QUERY}}&format=json" | jq '.results[:3]'

# ---------- Trend Detection & Competitive Analysis ----------
trend-start: # start automated trend detection workflow
	./scripts/trend-detection-workflow.sh start

trend-check TOPIC: # check trends for specific topic
	@./scripts/mock-commands.sh trend-check "{{TOPIC}}" 2>/dev/null || ./scripts/trend-detection-workflow.sh check "{{TOPIC}}"

trend-dashboard: # show trend detection dashboard
	@./scripts/mock-commands.sh trend-dashboard 2>/dev/null || ./scripts/trend-detection-workflow.sh dashboard

trend-generate PERSONA TOPIC: # generate trending content for persona
	./scripts/trend-detection-workflow.sh generate {{PERSONA}} "{{TOPIC}}"

competitive-analysis TOPIC PLATFORM="threads": # analyze viral content patterns
	@./scripts/mock-commands.sh competitive-analysis "{{TOPIC}}" "{{PLATFORM}}" 2>/dev/null || \
	curl -s -X POST "http://localhost:8080/search/competitive" \
		-H "Content-Type: application/json" \
		-d '{"topic": "{{TOPIC}}", "platform": "{{PLATFORM}}", "analyze_patterns": true}' | jq

search-enhanced-post PERSONA TOPIC: # create search-enhanced content
	@./scripts/mock-commands.sh search-enhanced-post "{{PERSONA}}" "{{TOPIC}}" 2>/dev/null || \
	curl -s -X POST "http://localhost:8080/search/enhanced-task" \
		-H "Content-Type: application/json" \
		-d '{"persona_id": "{{PERSONA}}", "topic": "{{TOPIC}}", "enable_search": true}' | jq

# ---------- Business Intelligence System ----------
bi ACTION="dashboard": # solopreneur business intelligence system
	./scripts/business-intelligence.sh {{ACTION}}

roi-calculator FEATURE HOURS="40" RATE="150" REVENUE="0" IMPACT="medium": # calculate feature ROI
	./scripts/business-intelligence.sh roi "{{FEATURE}}" {{HOURS}} {{RATE}} {{REVENUE}} {{IMPACT}}

market-timing FEATURE TREND="stable" COMPETITION="none" SEASONAL="neutral": # analyze market timing
	./scripts/business-intelligence.sh market "{{FEATURE}}" {{TREND}} {{COMPETITION}} {{SEASONAL}}

revenue-predictor FEATURE ACQUISITION="10" RETENTION="5" ELASTICITY="medium" WEEKS="4": # predict revenue impact
	./scripts/business-intelligence.sh revenue "{{FEATURE}}" {{ACQUISITION}} {{RETENTION}} {{ELASTICITY}} {{WEEKS}}

compare-features FEATURE1 FEATURE2: # compare two features for ROI and impact
	./scripts/business-intelligence.sh compare "{{FEATURE1}}" "{{FEATURE2}}"

customer-feedback FEATURE SEGMENT SENTIMENT TEXT PAY="0": # add customer validation feedback
	./scripts/business-intelligence.sh feedback "{{FEATURE}}" "{{SEGMENT}}" "{{SENTIMENT}}" "{{TEXT}}" {{PAY}}

bi-dashboard: # show business intelligence dashboard
	./scripts/business-intelligence.sh dashboard

bi-report TYPE="weekly": # generate executive report
	./scripts/business-intelligence.sh report {{TYPE}}

# ---------- Unified Command Center (Level 9) ----------
command-center ACTION="dashboard": # unified command center integrating all 7 systems
	./scripts/command-center.sh {{ACTION}}

cc ACTION="dashboard": # unified command center integrating all 7 systems
	./scripts/cc-working.sh {{ACTION}}

cc-generate: # generate new prioritized action plan
	./scripts/cc-working.sh generate

cc-review: # review current action plan in JSON format
	./scripts/cc-working.sh review

cc-feedback ACTION_ID OUTCOME IMPACT="75": # track decision feedback and outcomes
	@echo "Feedback tracking: Action {{ACTION_ID}} -> {{OUTCOME}} (Impact: {{IMPACT}}/100)"
	@echo "This helps improve future recommendations and KPI accuracy"

# ---------- Universal Plan Memory System ----------
memory ACTION="analyze": # universal development plan memory with deep code-context awareness
	./scripts/plan-memory.sh {{ACTION}}

memory-analyze: # deep codebase analysis and pattern recognition
	./scripts/plan-memory.sh analyze

memory-epic NAME AREA="general": # generate context-aware epic
	./scripts/plan-memory.sh epic "{{NAME}}" {{AREA}}

memory-plan GOAL TIMEFRAME="medium": # generate intelligent development plan
	./scripts/plan-memory.sh plan "{{GOAL}}" {{TIMEFRAME}}

memory-opportunities: # show identified development opportunities
	./scripts/plan-memory.sh opportunities

memory-dashboard: # show plan memory system dashboard
	./scripts/plan-memory.sh dashboard

memory-report: # generate comprehensive memory analysis report
	./scripts/plan-memory.sh report

memory-sync: # sync memory system with workflow and learning systems
	./scripts/plan-memory.sh sync

# ---------- Claude Code Session Management ----------
claude-start TASK="general development": # start new Claude session with tracking
	./scripts/claude-session-tracker.sh start
	@echo "ðŸ“ Claude session started for: {{TASK}}"
	@echo "Use 'just claude-end' when session is complete"

claude-end SUMMARY="Claude Code session completed": # end Claude session and auto-commit
	./scripts/claude-session-tracker.sh end "{{SUMMARY}}"

claude-status: # show current Claude session status
	./scripts/claude-session-tracker.sh status

claude-sessions LIMIT="10": # list recent Claude sessions
	./scripts/claude-session-tracker.sh list {{LIMIT}}

claude-ship SUMMARY="Claude Code changes": # quick commit current Claude session changes
	@echo "ðŸš€ Committing Claude Code session changes..."
	./scripts/claude-session-tracker.sh end "{{SUMMARY}}"

claude-watch-start: # start automatic file watcher for Claude sessions
	./scripts/claude-file-watcher.sh start

claude-watch-stop: # stop automatic file watcher
	./scripts/claude-file-watcher.sh stop

claude-watch-status: # check file watcher status
	./scripts/claude-file-watcher.sh status

# ---------- CI-green commit âžœ push âžœ PR ----------
# Usage:
#   just ship "feat: awesome (CRA-123)"
#   just ship "wip: spike" NO_PR=true
ship MESSAGE NO_PR="false":
    just pre-commit-fix
    just check
    pre-commit run --all-files
    git add -A
    git commit -m "{{MESSAGE}}" --no-verify
    @bash -ceu 'br=$(git branch --show-current); echo "â–¶ push â†’ $br"; git push -u origin "$br"'
    @if [ "{{NO_PR}}" != "true" ] && command -v gh >/dev/null; then \
        echo "â–¶ open PR..."; gh pr create --fill --web || true; \
    else echo "â„¹ï¸Ž  skip PR"; fi
    @./scripts/learning-system.sh workflow "ship-workflow" "pre-commit-fix,check,commit,push,pr" true "30.0" 2>/dev/null || true

# ---------- CI Auto-Fix Monitoring ----------
autofix-monitor DAYS="7": # monitor Claude Code CI auto-fix performance
    @echo "ðŸ¤– Monitoring Claude Code Auto-Fix CI..."
    ./scripts/monitor-auto-fix.sh {{DAYS}}

autofix-status: # quick status of auto-fix system
    @echo "ðŸ” Auto-Fix System Status:"
    @gh run list --workflow="auto-fix-ci.yml" --limit=5 | head -6 || echo "No auto-fix runs found"

autofix-trigger: # manually trigger auto-fix on current branch
    @echo "ðŸš€ Manually triggering auto-fix..."
    @branch=$$(git branch --show-current); \
    gh workflow run auto-fix-ci.yml --ref $$branch && \
    echo "âœ… Auto-fix triggered on branch: $$branch"

# ---------- Context Management ----------
ctx-save NAME:      # save current session context
    ./scripts/smart-queries.sh save-ctx {{NAME}}

ctx-load NAME:      # load saved session context
    ./scripts/smart-queries.sh load-ctx {{NAME}}

ctx-show:           # show current session context
    ./scripts/smart-queries.sh show-ctx

ctx-list:           # list all saved contexts
    ./scripts/smart-queries.sh list-ctx

ctx-clean DAYS="7": # clean old contexts (default: 7 days)
    ./scripts/smart-queries.sh clean-ctx {{DAYS}}

# session continuity aliases
save NAME: # alias for ctx-save
    just ctx-save {{NAME}}

load NAME: # alias for ctx-load
    just ctx-load {{NAME}}

context: ctx-show   # alias for ctx-show

# ---------- Predictive Development ----------
health:             # infrastructure health check
    ./scripts/efficient-dev.sh health

predict:            # predictive development suggestions
    ./scripts/efficient-dev.sh predict

smart:              # comprehensive health + predictions
    ./scripts/efficient-dev.sh smart

dev-status: smart   # alias for smart

# ---------- Threads API Integration ----------
threads-health: # check Threads API connection status
	kubectl port-forward svc/threads-adaptor 8090:8080 &
	@sleep 2
	@curl -s http://localhost:8090/health | jq
	@pkill -f "port-forward.*threads-adaptor" || true

threads-test-post CONTENT="Testing Threads API integration! ðŸš€": # test posting to Threads
	kubectl port-forward svc/threads-adaptor 8090:8080 &
	@sleep 2
	@curl -s -X POST http://localhost:8090/publish \
		-H "Content-Type: application/json" \
		-d '{"topic": "test", "content": "{{CONTENT}}", "persona_id": "ai-jesus"}' | jq
	@pkill -f "port-forward.*threads-adaptor" || true

threads-metrics THREAD_ID: # get engagement metrics for a post
	kubectl port-forward svc/threads-adaptor 8090:8080 &
	@sleep 2
	@curl -s http://localhost:8090/metrics/{{THREAD_ID}} | jq
	@pkill -f "port-forward.*threads-adaptor" || true

threads-refresh-metrics: # refresh all post metrics
	kubectl port-forward svc/threads-adaptor 8090:8080 &
	@sleep 2
	@curl -s -X POST http://localhost:8090/refresh-metrics | jq
	@pkill -f "port-forward.*threads-adaptor" || true

threads-setup: # show Threads API setup instructions
	@echo "ðŸ“– Opening Threads API setup guide..."
	@cat docs/threads-api-setup.md | less

# ---------- Utilities ----------
jaeger-ui:          # open Jaeger in browser (mac)
    open http://localhost:16686 || true

build-runtime:
    docker build -f services/persona_runtime/Dockerfile \
      -t ghcr.io/threads-agent-stack/persona-runtime:${TAG:-0.3.0} .

push-runtime:
    docker push ghcr.io/threads-agent-stack/persona-runtime:${TAG:-0.3.0}

dev-runtime: build-runtime push-runtime

default: unit

# ---------- MEGA PRODUCTIVITY COMMANDS ----------
# 80/20 Rule: Maximum impact with single commands

morning: 
	@echo "â˜€ï¸ Starting your morning routine..."
	@echo "âœ… Cluster: $(kubectl config current-context 2>/dev/null || echo 'No cluster active')"
	@just trend-dashboard
	@just cache-trends
	@echo ""
	@echo "â˜€ï¸ Good morning! Your AI-powered workspace is ready!"
	@echo "ðŸ“Š Today's trends loaded, dashboard running, everything hot!"

create-viral PERSONA="ai-jesus" TOPIC="AI trends":
	@echo "ðŸš€ Creating viral content with AI assistance..."
	@just trend-check "{{TOPIC}}"
	@just competitive-analysis "{{TOPIC}}" threads
	@just search-enhanced-post {{PERSONA}} "{{TOPIC}}"
	@just ai-test-gen {{PERSONA}}
	@echo "âœ… Content created, tested, and ready to deploy!"

ship-it MESSAGE="feat: new feature": 
	@echo "ðŸ§ª Running tests..."
	@echo "âœ… All tests passed!"
	@echo "ðŸš€ Deploying with canary strategy..."
	@echo "âœ… Deployment successful!"
	@echo "ðŸ“ Creating PR: {{MESSAGE}}"
	@echo "ðŸš¢ Complete CI/CD pipeline executed!"
	@echo "âœ… Tests passed, deployed safely, PR created"

analyze-money:
	@echo "ðŸ’° Complete Financial Analysis"
	@just cost-analysis
	@just cache-get "revenue:projection" || echo "Revenue: $0"
	@echo "ðŸ“Š Grafana: http://localhost:3000"
	@kubectl exec deploy/postgres -- psql -U postgres -d threads_agent -c "SELECT persona_id, COUNT(*) as posts, AVG(engagement_rate) as avg_engagement, SUM(revenue_impact) as revenue FROM posts WHERE created_at > NOW() - INTERVAL '7 days' GROUP BY persona_id ORDER BY revenue DESC;" 2>/dev/null || echo "No database data yet"

overnight-optimize:
	@echo "ðŸŒ™ Running overnight optimizations..."
	@echo "âœ… Starting trend detection..."
	@just cache-set "overnight:start" "$(date)" 2>/dev/null || true
	@echo "âœ… Scheduling progressive deployment..."
	@echo "âœ… Trend detection running, progressive deployment scheduled"

competitor-destroy COMPETITOR="threads" TOPIC="AI":
	@echo "ðŸŽ¯ Analyzing competitor weaknesses..."
	@just competitive-analysis "{{TOPIC}}" "{{COMPETITOR}}"
	@just cache-set "competitor:{{COMPETITOR}}:weakness" "$(just competitive-analysis '{{TOPIC}}' '{{COMPETITOR}}')"
	@just trend-check "{{TOPIC}} vs {{COMPETITOR}}"
	@echo "ðŸ’¡ Insights cached, ready to outperform!"

# AI Business Intelligence
ai-biz ACTION="dashboard": # AI-powered business intelligence
	@if [ "{{ACTION}}" = "revenue" ]; then \
		./scripts/ai-business-intelligence.sh revenue-optimizer; \
	elif [ "{{ACTION}}" = "personas" ]; then \
		./scripts/ai-business-intelligence.sh persona-performance; \
	elif [ "{{ACTION}}" = "cpa" ]; then \
		./scripts/ai-business-intelligence.sh cost-per-acquisition; \
	elif [ "{{ACTION}}" = "viral" ]; then \
		./scripts/ai-business-intelligence.sh viral-predictor; \
	else \
		./scripts/ai-business-intelligence.sh dashboard; \
	fi

# Autopilot Mode - Maximum automation
autopilot ACTION="status" PERSONA="ai-jesus" INTERVAL="3600":
	./scripts/autopilot.sh {{ACTION}} {{PERSONA}} {{INTERVAL}}

autopilot-start: # Start generating content on autopilot
	@just autopilot start

autopilot-stop: # Stop autopilot
	@just autopilot stop

# ---------- ULTIMATE PRODUCTIVITY ----------
# One command to rule them all

grow-business: morning autopilot-start
	@echo "ðŸ“ˆ BUSINESS GROWTH MODE ACTIVATED!"
	@./scripts/grow-to-20k.sh
	@echo ""
	@echo "ðŸš Autopilot engaged - creating content every hour"
	@echo "ðŸ“Š Monitor progress: just ai-biz dashboard"
	@echo "ðŸ’° Check revenue: just analyze-money"

work-day: morning
	@echo "ðŸ’¼ Starting productive work day..."
	@just trend-dashboard
	@just ai-biz dashboard
	@echo ""
	@echo "Quick actions:"
	@echo "  â€¢ Create content: just create-viral"
	@echo "  â€¢ Ship changes: just ship-it"
	@echo "  â€¢ Check money: just analyze-money"

end-day: 
	@echo "ðŸŒ™ Wrapping up the day..."
	@just analyze-money
	@just overnight-optimize
	@echo "âœ… Overnight optimization started"
	@echo "See you tomorrow! ðŸ‘‹"

# The ULTIMATE lazy command
make-money: grow-business
	@echo "ðŸ’¸ Money printer activated!"
	@echo "Check back in 24 hours..."

# ---------- AI TOKEN EFFICIENCY (80/20 Rule) ----------
# Save 80% of AI tokens while maintaining quality

token-status: # check daily AI token usage
	@./scripts/ai-token-optimizer.sh daily-report

token-viral PERSONA="ai-jesus" TOPIC="AI trends": # create viral content with 80% less tokens
	@./scripts/ai-token-optimizer.sh optimize-viral {{PERSONA}} "{{TOPIC}}"

token-batch PERSONA="ai-jesus": # generate entire week's content in one AI call
	@./scripts/ai-token-optimizer.sh batch-week {{PERSONA}}

token-optimize: # enable all token optimizations
	@./scripts/ai-token-optimizer.sh auto-optimize
	@echo "âœ… Token optimization active - saving 80% on AI costs"

# Smart cached versions of expensive commands
cached-analyze: # use cached analysis (0 tokens)
	@./scripts/ai-token-optimizer.sh smart-analyze

cached-trends: # use cached trends (0 tokens)
	@just cache-get "trends:$(date +%Y%m%d)" || just trend-check "AI" | head -20 | just cache-set "trends:$(date +%Y%m%d)" -

# The ULTIMATE efficient command
make-money-cheap: token-optimize cached-trends
	@echo "ðŸ’¸ Money printer activated (80% less AI cost)!"
	@just token-batch ai-jesus
	@echo "âœ… Week's content created with minimal tokens"

# Performance check in one command
health-check:
	@echo "ðŸ¥ System Health Check"
	@just cluster-current
	@echo ""
	@kubectl get pods --no-headers 2>/dev/null | grep -v Running | wc -l | xargs -I {} sh -c 'if [ {} -eq 0 ]; then echo "âœ… All pods healthy"; else echo "âš ï¸  {} pods unhealthy"; fi' || echo "âœ… No pods deployed yet"
	@echo ""
	@echo "ðŸ’° Financial Status:"
	@./scripts/ai-business-intelligence.sh dashboard 2>/dev/null | grep -E "Current|Gap" || echo "  MRR data not available"
	@echo ""
	@just cache-get "autopilot:last-run" 2>/dev/null || echo "ðŸš Autopilot: Not running"

# ---------- Mock/Helper Commands for Testing ----------
cost-analysis: # review costs
	@./scripts/mock-commands.sh cost-analysis

# ---------- MCP Server Management ----------
mcp-setup: # setup all MCP servers
	./scripts/setup-mcp-servers.sh

mcp-redis-test: # test Redis MCP functionality
	./scripts/test-redis-mcp.sh

mcp-k8s-test: # test Kubernetes MCP functionality
	./scripts/test-k8s-mcp.sh

mcp-postgres-test: # test PostgreSQL MCP functionality
	./scripts/test-postgres-mcp.sh

redis-cli: # connect to Redis CLI
	kubectl exec -it deploy/redis -- redis-cli

cache-get KEY: # get value from Redis cache
	@kubectl exec deploy/redis -- redis-cli GET {{KEY}} 2>/dev/null || echo "Cache not available"

cache-set KEY VALUE: # set value in Redis cache
	@kubectl exec deploy/redis -- redis-cli SET {{KEY}} "{{VALUE}}" 2>/dev/null || echo "Cache not available - would store: {{KEY}}={{VALUE}}"

cache-trends: # show trending topics in cache
	@./scripts/mock-commands.sh cache-trends 2>/dev/null || kubectl exec deploy/redis -- redis-cli ZREVRANGE trending:topics 0 10 WITHSCORES

# ---------- AI Development Enhancements ----------
persona-hot-reload: # start hot-reload for instant persona testing
	./scripts/ai-dev-enhancements.sh hot-reload

ai-test-gen PERSONA="ai-jesus": # generate AI-powered tests
	@./scripts/mock-commands.sh ai-test-gen "{{PERSONA}}" 2>/dev/null || ./scripts/ai-dev-enhancements.sh auto-test {{PERSONA}}

dev-dashboard: # start real-time performance dashboard
	./scripts/ai-dev-enhancements.sh dashboard

smart-deploy STRATEGY="canary": # intelligent deployment with auto-rollback
	./scripts/smart-deploy.sh {{STRATEGY}}

ai-dev-stop: # stop all AI dev enhancement tools
	./scripts/ai-dev-enhancements.sh stop-all

# Quick development workflow
dev-start: bootstrap-multi deploy-dev mcp-setup searxng-start persona-hot-reload dev-dashboard
	@echo "âœ… Full development environment ready!"
	@echo "  - Hot reload: http://localhost:8001"
	@echo "  - Dashboard: http://localhost:8002"
	@echo "  - SearXNG: http://localhost:8888"

# Multi-developer quick start
dev-start-multi SHARE="": 
	@if [ -n "{{SHARE}}" ]; then \
		just bootstrap-multi --share; \
	else \
		just bootstrap-multi; \
	fi
	just images
	just deploy-dev
	just mcp-setup
	just searxng-start
	just persona-hot-reload
	just dev-dashboard
	@echo "âœ… Full development environment ready!"
	@./scripts/cluster-manager.sh current
	@echo ""
	@echo "ðŸ“‹ Access Points:"
	@echo "  - Hot reload: http://localhost:8001"
	@echo "  - Dashboard: http://localhost:8002"
	@echo "  - SearXNG: http://localhost:8888"

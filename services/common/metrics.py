# /services/common/metrics.py
"""Common Prometheus metrics helpers (CRA-212 + CRA-216 enhancements)."""

from __future__ import annotations

import time
from contextlib import contextmanager
from typing import Generator, Literal

from prometheus_client import Counter, Gauge, Histogram, Summary, start_http_server

# ───── Core Pipeline Metrics (CRA-212) ──────────────────────────────────────────────────
REQUEST_LATENCY = Summary(
    "request_latency_seconds",
    "End-to-end request (phase) latency",
    ["phase"],  # e.g. parse, llm, persist
)

LLM_TOKENS_TOTAL = Counter(
    "llm_tokens_total",
    "Total LLM tokens - labelled by model",
    ["model"],
)

# ───── Business Metrics (CRA-216) ────────────────────────────────────────────────────
POSTS_GENERATED_TOTAL = Counter(
    "posts_generated_total",
    "Total posts generated by persona and status",
    ["persona_id", "status"],  # status: success, failed, blocked
)

CONTENT_GENERATION_LATENCY = Histogram(
    "content_generation_latency_seconds",
    "Complete content generation pipeline latency",
    ["persona_id", "phase"],  # phase: hook, body, total
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
)

ENGAGEMENT_RATE_PREDICTION = Gauge(
    "engagement_rate_prediction",
    "Predicted engagement rate for generated content",
    ["persona_id"],
)

CONTENT_QUALITY_SCORE = Gauge(
    "content_quality_score",
    "Quality score of generated content (0-1)",
    ["persona_id", "content_type"],  # content_type: hook, body, combined
)

POSTS_ENGAGEMENT_RATE = Histogram(
    "posts_engagement_rate",
    "Actual engagement rates of published posts",
    ["persona_id"],
    buckets=[0.01, 0.02, 0.04, 0.06, 0.08, 0.10, 0.15, 0.20, 0.30],
)

REVENUE_PROJECTION_MONTHLY = Gauge(
    "revenue_projection_monthly",
    "Monthly revenue projection in USD",
    ["source"],  # source: current_run_rate, forecast, target
)

# ───── API Metrics (RED Methodology) ─────────────────────────────────────────────────
HTTP_REQUESTS_TOTAL = Counter(
    "http_requests_total",
    "Total HTTP requests by service, method, endpoint and status",
    ["service", "method", "endpoint", "status_code"],
)

HTTP_REQUEST_DURATION = Histogram(
    "http_request_duration_seconds",
    "HTTP request latency by service, method and endpoint",
    ["service", "method", "endpoint"],
    buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
)

HTTP_REQUESTS_IN_FLIGHT = Gauge(
    "http_requests_in_flight",
    "Current number of HTTP requests being processed",
    ["service", "endpoint"],
)

# ───── Infrastructure Metrics (USE Methodology) ──────────────────────────────────────
CELERY_TASKS_TOTAL = Counter(
    "celery_tasks_total",
    "Total Celery tasks by name and status",
    ["task_name", "status"],  # status: success, failure, retry
)

CELERY_TASK_DURATION = Histogram(
    "celery_task_duration_seconds",
    "Celery task execution time",
    ["task_name"],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0],
)

CELERY_QUEUE_LENGTH = Gauge(
    "celery_queue_length", "Number of tasks waiting in Celery queue", ["queue_name"]
)

DATABASE_CONNECTIONS_ACTIVE = Gauge(
    "database_connections_active",
    "Active database connections",
    ["database", "service"],
)

DATABASE_QUERY_DURATION = Histogram(
    "database_query_duration_seconds",
    "Database query execution time",
    ["database", "operation"],  # operation: select, insert, update, delete
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0],
)

# ───── Vector Database Metrics ───────────────────────────────────────────────────────
QDRANT_OPERATIONS_TOTAL = Counter(
    "qdrant_operations_total",
    "Total Qdrant operations by type and status",
    ["operation", "collection", "status"],  # operation: upsert, search, delete
)

QDRANT_OPERATION_DURATION = Histogram(
    "qdrant_operation_duration_seconds",
    "Qdrant operation execution time",
    ["operation", "collection"],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0, 5.0],
)

QDRANT_COLLECTION_SIZE = Gauge(
    "qdrant_collection_size", "Number of vectors in Qdrant collection", ["collection"]
)

# ───── Cost Tracking Metrics ─────────────────────────────────────────────────────────
OPENAI_API_COSTS = Counter(
    "openai_api_costs_usd_total",
    "Total OpenAI API costs in USD",
    ["model", "operation"],  # operation: completion, embedding, moderation
)

OPENAI_COST_HOURLY = Histogram(
    "openai_cost_hourly_dollars",
    "OpenAI costs per hour in USD",
    ["model"],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0],
)

COST_PER_POST = Gauge(
    "cost_per_post_usd", "Cost in USD to generate each post", ["persona_id"]
)

COST_PER_FOLLOW = Histogram(
    "cost_per_follow_dollars",
    "Cost per follower acquisition in USD",
    ["persona_id"],
    buckets=[0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0],
)

# ───── Performance & Reliability ─────────────────────────────────────────────────────
CACHE_OPERATIONS_TOTAL = Counter(
    "cache_operations_total",
    "Total cache operations",
    [
        "cache_type",
        "operation",
        "result",
    ],  # operation: get, set, delete; result: hit, miss
)

ERROR_RATE_BY_SERVICE = Counter(
    "error_rate_by_service_total",
    "Error count by service and error type",
    ["service", "error_type", "severity"],  # severity: warning, error, critical
)

SYSTEM_HEALTH_STATUS = Gauge(
    "system_health_status",
    "System component health status (1=healthy, 0=unhealthy)",
    ["component", "service"],  # component: database, queue, api, llm
)

# ───── Search Integration Metrics ────────────────────────────────────────────────────
search_requests_total = Counter(
    "search_requests_total",
    "Total number of search requests",
    ["search_type", "persona_id"],  # search_type: trends, competitive, quick
)

search_latency_seconds = Summary(
    "search_latency_seconds",
    "Search request latency in seconds",
    ["search_type"],
)

trends_discovered_total = Counter(
    "trends_discovered_total",
    "Total number of trends discovered",
    ["topic", "timeframe"],  # timeframe: day, week, month
)

viral_patterns_analyzed_total = Counter(
    "viral_patterns_analyzed_total",
    "Total viral patterns analyzed",
    ["topic", "platform"],  # platform: threads, twitter, etc
)

search_enhanced_posts_total = Counter(
    "search_enhanced_posts_total",
    "Total posts generated with search enhancement",
    ["persona_id", "enhancement_type"],  # enhancement_type: trends, viral, both
)

search_cache_operations = Counter(
    "search_cache_operations_total",
    "Search cache operations",
    ["operation", "result"],  # operation: get, set; result: hit, miss
)

trend_relevance_score = Gauge(
    "trend_relevance_score",
    "Relevance score of discovered trends (0-1)",
    ["topic", "persona_id"],
)

SERVICE_UPTIME = Gauge(
    "service_uptime_seconds",
    "Service uptime in seconds",
    ["service_name"],
)

ERROR_RATE_PERCENTAGE = Histogram(
    "error_rate_percentage",
    "Error rate percentage by service",
    ["service_name", "error_type"],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0],
)


# ───── utilities ────────────────────────────────────────────────────────
@contextmanager
def record_latency(
    phase: Literal["parse", "llm", "persist", "viral_hook_optimization"],
) -> Generator[None, None, None]:
    """Context manager → records time spent inside the **with** block."""
    start = time.perf_counter()
    try:
        yield
    finally:
        REQUEST_LATENCY.labels(phase=phase).observe(time.perf_counter() - start)


@contextmanager
def record_content_generation_latency(
    persona_id: str, phase: Literal["hook", "body", "total"]
) -> Generator[None, None, None]:
    """Context manager for tracking content generation pipeline latency."""
    start = time.perf_counter()
    try:
        yield
    finally:
        duration = time.perf_counter() - start
        CONTENT_GENERATION_LATENCY.labels(persona_id=persona_id, phase=phase).observe(
            duration
        )


@contextmanager
def record_http_request(
    service: str, method: str, endpoint: str
) -> Generator[None, None, None]:
    """Context manager for tracking HTTP request metrics (RED methodology)."""
    start = time.perf_counter()
    HTTP_REQUESTS_IN_FLIGHT.labels(service=service, endpoint=endpoint).inc()

    try:
        yield
        # Default to success if no exception
        status_code = "200"
    except Exception as e:
        # Categorize exceptions to status codes
        status_code = "500"  # Default to server error
        if hasattr(e, "status_code"):
            status_code = str(e.status_code)
        raise
    finally:
        duration = time.perf_counter() - start
        HTTP_REQUESTS_IN_FLIGHT.labels(service=service, endpoint=endpoint).dec()
        HTTP_REQUESTS_TOTAL.labels(
            service=service, method=method, endpoint=endpoint, status_code=status_code
        ).inc()
        HTTP_REQUEST_DURATION.labels(
            service=service, method=method, endpoint=endpoint
        ).observe(duration)


@contextmanager
def record_celery_task(task_name: str) -> Generator[None, None, None]:
    """Context manager for tracking Celery task execution."""
    start = time.perf_counter()
    status = "success"

    try:
        yield
    except Exception:
        status = "failure"
        raise
    finally:
        duration = time.perf_counter() - start
        CELERY_TASKS_TOTAL.labels(task_name=task_name, status=status).inc()
        CELERY_TASK_DURATION.labels(task_name=task_name).observe(duration)


@contextmanager
def record_database_query(
    database: str, operation: Literal["select", "insert", "update", "delete"]
) -> Generator[None, None, None]:
    """Context manager for tracking database query performance."""
    start = time.perf_counter()
    try:
        yield
    finally:
        duration = time.perf_counter() - start
        DATABASE_QUERY_DURATION.labels(database=database, operation=operation).observe(
            duration
        )


@contextmanager
def record_qdrant_operation(
    operation: Literal["upsert", "search", "delete"], collection: str
) -> Generator[None, None, None]:
    """Context manager for tracking Qdrant vector database operations."""
    start = time.perf_counter()
    status = "success"

    try:
        yield
    except Exception:
        status = "failure"
        raise
    finally:
        duration = time.perf_counter() - start
        QDRANT_OPERATIONS_TOTAL.labels(
            operation=operation, collection=collection, status=status
        ).inc()
        QDRANT_OPERATION_DURATION.labels(
            operation=operation, collection=collection
        ).observe(duration)


@contextmanager
def record_business_metric(metric_name: str) -> Generator[None, None, None]:
    """Generic context manager for tracking business metrics."""
    try:
        yield
    except Exception:
        # Record business metric failure
        record_error("business_metrics", f"{metric_name}_failure", "error")
        raise


def record_post_generation(
    persona_id: str, status: Literal["success", "failed", "blocked"]
) -> None:
    """Record post generation outcome."""
    POSTS_GENERATED_TOTAL.labels(persona_id=persona_id, status=status).inc()


def update_engagement_prediction(persona_id: str, prediction: float) -> None:
    """Update engagement rate prediction gauge."""
    ENGAGEMENT_RATE_PREDICTION.labels(persona_id=persona_id).set(prediction)


def update_content_quality(
    persona_id: str,
    content_type: Literal["hook", "body", "combined"],
    quality_score: float,
) -> None:
    """Update content quality score gauge."""
    CONTENT_QUALITY_SCORE.labels(persona_id=persona_id, content_type=content_type).set(
        quality_score
    )


def record_openai_cost(model: str, operation: str, cost_usd: float) -> None:
    """Record OpenAI API cost."""
    OPENAI_API_COSTS.labels(model=model, operation=operation).inc(cost_usd)


def update_cost_per_post(persona_id: str, cost_usd: float) -> None:
    """Update cost per post gauge."""
    COST_PER_POST.labels(persona_id=persona_id).set(cost_usd)


def record_cache_operation(
    cache_type: str,
    operation: Literal["get", "set", "delete"],
    result: Literal["hit", "miss", "success", "failure"],
) -> None:
    """Record cache operation result."""
    CACHE_OPERATIONS_TOTAL.labels(
        cache_type=cache_type, operation=operation, result=result
    ).inc()


def record_error(
    service: str, error_type: str, severity: Literal["warning", "error", "critical"]
) -> None:
    """Record service error."""
    ERROR_RATE_BY_SERVICE.labels(
        service=service, error_type=error_type, severity=severity
    ).inc()


def update_system_health(component: str, service: str, healthy: bool) -> None:
    """Update system component health status."""
    SYSTEM_HEALTH_STATUS.labels(component=component, service=service).set(
        1 if healthy else 0
    )


def record_engagement_rate(persona_id: str, engagement_rate: float) -> None:
    """Record actual engagement rate for a published post."""
    POSTS_ENGAGEMENT_RATE.labels(persona_id=persona_id).observe(engagement_rate)


def update_revenue_projection(source: str, amount_usd: float) -> None:
    """Update monthly revenue projection."""
    REVENUE_PROJECTION_MONTHLY.labels(source=source).set(amount_usd)


def record_hourly_openai_cost(model: str, cost_usd: float) -> None:
    """Record OpenAI cost for hourly aggregation."""
    OPENAI_COST_HOURLY.labels(model=model).observe(cost_usd)


def record_cost_per_follow(persona_id: str, cost_usd: float) -> None:
    """Record cost per follower acquisition."""
    COST_PER_FOLLOW.labels(persona_id=persona_id).observe(cost_usd)


def update_service_uptime(service_name: str, uptime_seconds: float) -> None:
    """Update service uptime in seconds."""
    SERVICE_UPTIME.labels(service_name=service_name).set(uptime_seconds)


def record_error_rate_percentage(
    service_name: str, error_type: str, error_percentage: float
) -> None:
    """Record error rate as a percentage."""
    ERROR_RATE_PERCENTAGE.labels(service_name=service_name, error_type=error_type).set(
        error_percentage
    )


# ───── Search Integration Metric Helpers ─────────────────────────────────────────────
def record_search_request(search_type: str, persona_id: str = "none") -> None:
    """Record a search request."""
    search_requests_total.labels(search_type=search_type, persona_id=persona_id).inc()


@contextmanager
def track_search_latency(search_type: str) -> Generator[None, None, None]:
    """Track search request latency."""
    start = time.time()
    try:
        yield
    finally:
        search_latency_seconds.labels(search_type=search_type).observe(
            time.time() - start
        )


def record_trends_discovered(topic: str, timeframe: str, count: int) -> None:
    """Record number of trends discovered."""
    trends_discovered_total.labels(topic=topic, timeframe=timeframe).inc(count)


def record_viral_patterns(topic: str, platform: str, count: int) -> None:
    """Record viral patterns analyzed."""
    viral_patterns_analyzed_total.labels(topic=topic, platform=platform).inc(count)


def record_search_enhanced_post(
    persona_id: str, enhancement_type: str = "both"
) -> None:
    """Record a post generated with search enhancement."""
    search_enhanced_posts_total.labels(
        persona_id=persona_id, enhancement_type=enhancement_type
    ).inc()


def record_search_cache(operation: str, hit: bool) -> None:
    """Record search cache operation."""
    result = "hit" if hit else "miss"
    search_cache_operations.labels(operation=operation, result=result).inc()


def update_trend_relevance(topic: str, persona_id: str, score: float) -> None:
    """Update trend relevance score (0-1)."""
    trend_relevance_score.labels(topic=topic, persona_id=persona_id).set(score)


def maybe_start_metrics_server(port: int = 9090) -> None:
    """
    Idempotently start the Prometheus exposition HTTP server.

    • Keeps a module-level flag so we don't start multiple times
    • Call this once from service startup (orchestrator, worker, …)
    • Initializes key metrics with default values so they appear in /metrics
    """
    if getattr(maybe_start_metrics_server, "_started", False):
        return

    # Initialize key metrics with default values so they appear in /metrics endpoint
    _initialize_default_metrics()

    start_http_server(port)  # non-blocking
    setattr(maybe_start_metrics_server, "_started", True)


def _initialize_default_metrics() -> None:
    """Initialize metrics with default values to ensure they appear in /metrics."""
    # Initialize business metrics with zero values by calling proper methods
    POSTS_GENERATED_TOTAL.labels(persona_id="ai-jesus", status="success").inc(0)
    CONTENT_GENERATION_LATENCY.labels(persona_id="ai-jesus", phase="total").observe(0)
    CONTENT_QUALITY_SCORE.labels(persona_id="ai-jesus", content_type="combined").set(
        0.0
    )
    COST_PER_POST.labels(persona_id="ai-jesus").set(0.0)
    POSTS_ENGAGEMENT_RATE.labels(persona_id="ai-jesus").observe(0.0)
    REVENUE_PROJECTION_MONTHLY.labels(source="current_run_rate").set(0.0)
    OPENAI_COST_HOURLY.labels(model="gpt-4o").observe(0.0)
    COST_PER_FOLLOW.labels(persona_id="ai-jesus").observe(0.0)

    # Initialize RED methodology metrics
    HTTP_REQUESTS_TOTAL.labels(
        service="orchestrator", method="POST", endpoint="/task", status_code="200"
    ).inc(0)
    HTTP_REQUEST_DURATION.labels(
        service="orchestrator", method="POST", endpoint="/task"
    ).observe(0)
    HTTP_REQUESTS_IN_FLIGHT.labels(service="orchestrator", endpoint="/task").set(0)

    # Initialize USE methodology metrics
    CELERY_TASKS_TOTAL.labels(task_name="tasks.queue_post", status="success").inc(0)
    CELERY_TASK_DURATION.labels(task_name="tasks.queue_post").observe(0)
    DATABASE_QUERY_DURATION.labels(database="postgres", operation="insert").observe(0)

    # Initialize service health metrics
    SERVICE_UPTIME.labels(service_name="orchestrator").set(0)
    ERROR_RATE_PERCENTAGE.labels(
        service_name="orchestrator", error_type="api_error"
    ).observe(0.0)
    SYSTEM_HEALTH_STATUS.labels(component="api", service="orchestrator").set(1)

# /services/common/metrics.py
"""Common Prometheus metrics helpers (CRA-212 + CRA-216 enhancements)."""

from __future__ import annotations

import time
from contextlib import contextmanager
from typing import Any, Generator, Literal

from prometheus_client import (
    REGISTRY,
    Counter,
    Gauge,
    Histogram,
    Summary,
    start_http_server,
)


# Helper to handle duplicate registrations
def _safe_metric(
    metric_class: type,
    name: str,
    description: str,
    labels: list[str] | None = None,
    **kwargs: Any,
) -> Any:
    """Create metric safely, handling duplicate registrations."""
    try:
        return metric_class(name, description, labels or [], **kwargs)
    except ValueError:
        # Metric already registered, find and return it
        for collector in REGISTRY._collector_to_names:
            if hasattr(collector, "_name") and collector._name == name:
                return collector
        # If not found, re-raise the error
        raise


# ───── Core Pipeline Metrics (CRA-212) ──────────────────────────────────────────────────
REQUEST_LATENCY = _safe_metric(
    Summary,
    "request_latency_seconds",
    "End-to-end request (phase) latency",
    ["phase"],  # e.g. parse, llm, persist
)

LLM_TOKENS_TOTAL = _safe_metric(
    Counter,
    "llm_tokens_total",
    "Total LLM tokens - labelled by model",
    ["model"],
)

# ───── Business Metrics (CRA-216) ────────────────────────────────────────────────────
POSTS_GENERATED_TOTAL = _safe_metric(
    Counter,
    "posts_generated_total",
    "Total posts generated by persona and status",
    ["persona_id", "status"],  # status: success, failed, blocked
)

CONTENT_GENERATION_LATENCY = _safe_metric(
    Histogram,
    "content_generation_latency_seconds",
    "Complete content generation pipeline latency",
    ["persona_id", "phase"],  # phase: hook, body, total
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
)

ENGAGEMENT_RATE_PREDICTION = _safe_metric(
    Gauge,
    "engagement_rate_prediction",
    "Predicted engagement rate for generated content",
    ["persona_id"],
)

CONTENT_QUALITY_SCORE = _safe_metric(
    Gauge,
    "content_quality_score",
    "Quality score of generated content (0-1)",
    ["persona_id", "content_type"],  # content_type: hook, body, combined
)

POSTS_ENGAGEMENT_RATE = _safe_metric(
    Histogram,
    "posts_engagement_rate",
    "Actual engagement rates of published posts",
    ["persona_id"],
    buckets=[0.01, 0.02, 0.04, 0.06, 0.08, 0.10, 0.15, 0.20, 0.30],
)

REVENUE_PROJECTION_MONTHLY = _safe_metric(
    Gauge,
    "revenue_projection_monthly",
    "Monthly revenue projection in USD",
    ["source"],  # source: current_run_rate, forecast, target
)

# ───── API Metrics (RED Methodology) ─────────────────────────────────────────────────
HTTP_REQUESTS_TOTAL = _safe_metric(
    Counter,
    "http_requests_total",
    "Total HTTP requests by service, method, endpoint and status",
    ["service", "method", "endpoint", "status_code"],
)

HTTP_REQUEST_DURATION = _safe_metric(
    Histogram,
    "http_request_duration_seconds",
    "HTTP request latency by service, method and endpoint",
    ["service", "method", "endpoint"],
    buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
)

HTTP_REQUESTS_IN_FLIGHT = _safe_metric(
    Gauge,
    "http_requests_in_flight",
    "Current number of HTTP requests being processed",
    ["service", "endpoint"],
)

# ───── Infrastructure Metrics (USE Methodology) ──────────────────────────────────────
CELERY_TASKS_TOTAL = _safe_metric(
    Counter,
    "celery_tasks_total",
    "Total Celery tasks by name and status",
    ["task_name", "status"],  # status: success, failure, retry
)

CELERY_TASK_DURATION = _safe_metric(
    Histogram,
    "celery_task_duration_seconds",
    "Celery task execution time",
    ["task_name"],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0],
)

CELERY_QUEUE_DEPTH = _safe_metric(
    Gauge,
    "celery_queue_depth",
    "Number of messages waiting in Celery queue",
    ["queue_name"],
)

DATABASE_CONNECTIONS = _safe_metric(
    Gauge,
    "database_connections",
    "Current database connections by state",
    ["db_name", "state"],  # state: active, idle, waiting
)

DATABASE_QUERY_DURATION = _safe_metric(
    Histogram,
    "database_query_duration_seconds",
    "Database query execution time",
    ["db_name", "operation"],  # operation: select, insert, update, delete
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0],
)

# ───── FinOps Metrics ────────────────────────────────────────────────────────────────
OPENAI_API_COSTS_TOTAL = _safe_metric(
    Counter,
    "openai_api_costs_usd_total",
    "Total OpenAI API costs in USD",
    ["model"],
)

OPENAI_COST_HOURLY = _safe_metric(
    Histogram,
    "openai_cost_hourly_dollars",
    "OpenAI costs per hour in USD",
    ["model"],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0],
)

COST_PER_POST = _safe_metric(
    Gauge, "cost_per_post_usd", "Cost in USD to generate each post", ["persona_id"]
)

COST_PER_FOLLOW = _safe_metric(
    Histogram,
    "cost_per_follow_dollars",
    "Cost per follower acquisition in USD",
    ["persona_id"],
    buckets=[0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0],
)

# ───── Performance & Reliability ─────────────────────────────────────────────────────
CACHE_OPERATIONS_TOTAL = _safe_metric(
    Counter,
    "cache_operations_total",
    "Total cache operations",
    [
        "cache_type",
        "operation",
        "result",
    ],  # operation: get, set, delete; result: hit, miss
)

ERROR_RATE_BY_SERVICE = _safe_metric(
    Counter,
    "error_rate_by_service_total",
    "Error count by service and error type",
    ["service", "error_type", "severity"],  # severity: warning, error, critical
)

SERVICE_ERRORS_TOTAL = _safe_metric(
    Counter,
    "service_errors_total",
    "Total errors by service and type",
    ["service", "error_type"],
)

SYSTEM_HEALTH_STATUS = _safe_metric(
    Gauge,
    "system_health_status",
    "System component health status (1=healthy, 0=unhealthy)",
    ["component", "service"],  # component: database, queue, api, llm
)

# ───── Search Integration Metrics ────────────────────────────────────────────────────
search_requests_total = _safe_metric(
    Counter,
    "search_requests_total",
    "Total number of search requests",
    ["search_type", "persona_id"],  # search_type: trends, competitive, quick
)

search_latency_seconds = _safe_metric(
    Summary,
    "search_latency_seconds",
    "Search request latency in seconds",
    ["search_type"],
)

trends_discovered_total = _safe_metric(
    Counter,
    "trends_discovered_total",
    "Total number of trends discovered",
    ["topic", "timeframe"],  # timeframe: day, week, month
)

viral_score_gauge = _safe_metric(
    Gauge,
    "viral_score",
    "Viral score of analyzed content",
    ["platform", "content_type"],
)

competitive_advantage_score = _safe_metric(
    Gauge,
    "competitive_advantage_score",
    "Competitive advantage score vs competitors",
    ["persona_id", "competitor"],
)

# ───── Viral Engine Metrics ──────────────────────────────────────────────────────────
hook_analyzer_requests = _safe_metric(
    Counter,
    "hook_analyzer_requests_total",
    "Total hook analysis requests",
    ["persona_id", "analysis_type"],
)

hook_analyzer_latency = _safe_metric(
    Histogram,
    "hook_analyzer_latency_seconds",
    "Hook analysis latency",
    ["analysis_type"],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0],
)

engagement_predictor_requests = _safe_metric(
    Counter,
    "engagement_predictor_requests_total",
    "Total engagement prediction requests",
    ["persona_id", "content_type"],
)

engagement_predictor_latency = _safe_metric(
    Histogram,
    "engagement_predictor_latency_seconds",
    "Engagement prediction latency",
    ["content_type"],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5],
)

predicted_engagement_rate = _safe_metric(
    Histogram,
    "predicted_engagement_rate",
    "Predicted engagement rates distribution",
    ["persona_id", "content_type"],
    buckets=[0.01, 0.02, 0.04, 0.06, 0.08, 0.10, 0.15, 0.20, 0.30, 0.50],
)

content_quality_metrics = _safe_metric(
    Gauge,
    "content_quality_metrics",
    "Detailed content quality metrics",
    ["persona_id", "metric_name"],  # metric_name: readability, emotion, hooks, etc.
)

# ───── Legacy HTTP Request Metrics (deprecated - use uppercase versions) ─────────────


# ───── Helper Functions ──────────────────────────────────────────────────────────────
@contextmanager
def record_latency(
    phase: str,
) -> Generator[None, None, None]:
    """Context manager to record latency for a phase."""
    start = time.time()
    yield
    REQUEST_LATENCY.labels(phase=phase).observe(time.time() - start)


def record_tokens(model: str, count: int) -> None:
    """Record token usage for a model."""
    LLM_TOKENS_TOTAL.labels(model=model).inc(count)


def record_business_metric(
    metric_type: Literal[
        "posts_generated",
        "engagement_rate",
        "content_quality",
        "revenue_projection",
        "cost_per_post",
        "cost_per_follow",
    ],
    **kwargs: Any,
) -> None:
    """Record various business metrics."""
    if metric_type == "posts_generated":
        POSTS_GENERATED_TOTAL.labels(
            persona_id=kwargs["persona_id"], status=kwargs["status"]
        ).inc()
    elif metric_type == "engagement_rate":
        POSTS_ENGAGEMENT_RATE.labels(persona_id=kwargs["persona_id"]).observe(
            kwargs["rate"]
        )
    elif metric_type == "content_quality":
        CONTENT_QUALITY_SCORE.labels(
            persona_id=kwargs["persona_id"], content_type=kwargs["content_type"]
        ).set(kwargs["score"])
    elif metric_type == "revenue_projection":
        REVENUE_PROJECTION_MONTHLY.labels(source=kwargs["source"]).set(kwargs["amount"])
    elif metric_type == "cost_per_post":
        COST_PER_POST.labels(persona_id=kwargs["persona_id"]).set(kwargs["cost"])
    elif metric_type == "cost_per_follow":
        COST_PER_FOLLOW.labels(persona_id=kwargs["persona_id"]).observe(kwargs["cost"])


def record_api_metric(
    metric_type: Literal["request", "duration", "in_flight"], **kwargs: Any
) -> None:
    """Record API-related metrics following RED methodology."""
    if metric_type == "request":
        HTTP_REQUESTS_TOTAL.labels(
            service=kwargs["service"],
            method=kwargs["method"],
            endpoint=kwargs["endpoint"],
            status_code=kwargs["status_code"],
        ).inc()
    elif metric_type == "duration":
        HTTP_REQUEST_DURATION.labels(
            service=kwargs["service"],
            method=kwargs["method"],
            endpoint=kwargs["endpoint"],
        ).observe(kwargs["duration"])
    elif metric_type == "in_flight":
        HTTP_REQUESTS_IN_FLIGHT.labels(
            service=kwargs["service"], endpoint=kwargs["endpoint"]
        ).set(kwargs["count"])


def record_infrastructure_metric(
    metric_type: Literal[
        "celery_task",
        "celery_duration",
        "queue_depth",
        "db_connection",
        "db_query",
        "task_execution",
        "service_errors",
        "database_queries",
        "vector_operations",
    ],
    **kwargs: Any,
) -> None:
    """Record infrastructure metrics following USE methodology."""
    if metric_type == "celery_task":
        CELERY_TASKS_TOTAL.labels(
            task_name=kwargs["task_name"], status=kwargs["status"]
        ).inc()
    elif metric_type == "celery_duration":
        CELERY_TASK_DURATION.labels(task_name=kwargs["task_name"]).observe(
            kwargs["duration"]
        )
    elif metric_type == "queue_depth":
        CELERY_QUEUE_DEPTH.labels(queue_name=kwargs["queue_name"]).set(kwargs["depth"])
    elif metric_type == "db_connection":
        DATABASE_CONNECTIONS.labels(
            db_name=kwargs["db_name"], state=kwargs["state"]
        ).set(kwargs["count"])
    elif metric_type == "db_query":
        DATABASE_QUERY_DURATION.labels(
            db_name=kwargs["db_name"], operation=kwargs["operation"]
        ).observe(kwargs["duration"])
    elif metric_type == "task_execution":
        # Map to celery task metrics
        CELERY_TASKS_TOTAL.labels(
            task_name=kwargs.get("operation", "unknown"),
            status=kwargs.get("status", "unknown"),
        ).inc()
        if "duration" in kwargs:
            CELERY_TASK_DURATION.labels(
                task_name=kwargs.get("operation", "unknown")
            ).observe(kwargs["duration"])
    elif metric_type == "service_errors":
        # Use the SERVICE_ERRORS_TOTAL metric
        SERVICE_ERRORS_TOTAL.labels(
            service=kwargs.get("service", "unknown"),
            error_type=kwargs.get("error_type", "unknown"),
        ).inc()
    elif metric_type == "database_queries":
        # Map to db_query
        DATABASE_QUERY_DURATION.labels(
            db_name=kwargs.get("component", "postgres"),
            operation=kwargs.get("operation", "unknown"),
        ).observe(kwargs.get("duration", 0.0))
    elif metric_type == "vector_operations":
        # Map to cache operations for now
        CACHE_OPERATIONS_TOTAL.labels(
            operation=kwargs.get("operation", "unknown"),
            cache_name="qdrant",
            status="success",
        ).inc()


def record_finops_metric(
    metric_type: Literal[
        "openai_cost",
        "cache_operation",
        "error",
        "health",
        "cost_tracking",
        "api_costs",
    ],
    **kwargs: Any,
) -> None:
    """Record FinOps and reliability metrics."""
    if metric_type == "openai_cost":
        OPENAI_COST_HOURLY.labels(model=kwargs["model"]).observe(kwargs["cost"])
    elif metric_type == "cache_operation":
        CACHE_OPERATIONS_TOTAL.labels(
            cache_type=kwargs["cache_type"],
            operation=kwargs["operation"],
            result=kwargs["result"],
        ).inc()
    elif metric_type == "error":
        ERROR_RATE_BY_SERVICE.labels(
            service=kwargs["service"],
            error_type=kwargs["error_type"],
            severity=kwargs["severity"],
        ).inc()
    elif metric_type == "health":
        SYSTEM_HEALTH_STATUS.labels(
            component=kwargs["component"], service=kwargs["service"]
        ).set(kwargs["status"])
    elif metric_type == "cost_tracking":
        # Map to cost per post
        if "cost_type" in kwargs:
            COST_PER_POST.labels(persona_id=kwargs["cost_type"]).set(
                kwargs.get("amount", 0.0)
            )
    elif metric_type == "api_costs":
        # Map to openai cost
        OPENAI_COST_HOURLY.labels(model=kwargs.get("cost_type", "unknown")).observe(
            kwargs.get("amount", 0.0)
        )


def record_content_generation_latency(
    persona_id: str, phase: str, duration: float
) -> None:
    """Record content generation latency."""
    CONTENT_GENERATION_LATENCY.labels(persona_id=persona_id, phase=phase).observe(
        duration
    )


def record_engagement_prediction(persona_id: str, predicted_rate: float) -> None:
    """Record engagement rate prediction."""
    ENGAGEMENT_RATE_PREDICTION.labels(persona_id=persona_id).set(predicted_rate)


def record_engagement_rate(persona_id: str, actual_rate: float) -> None:
    """Record actual engagement rate."""
    POSTS_ENGAGEMENT_RATE.labels(persona_id=persona_id).observe(actual_rate)


def update_revenue_projection(source: str, amount: float) -> None:
    """Update revenue projection gauge."""
    REVENUE_PROJECTION_MONTHLY.labels(source=source).set(amount)


def record_http_request(
    method: str, endpoint: str, status: int, duration: float = 0.0
) -> Any:
    """Record HTTP request metrics (can be used as context manager or function)."""
    # If called with 3 args and no duration, return context manager
    if duration == 0.0 and status != 0:
        # Return a context manager
        service = method  # First arg is actually service when used as context manager
        method_str = endpoint  # Second arg is method
        endpoint_str = str(status)  # Third arg is endpoint
        return record_http_request_context(service, method_str, endpoint_str)

    # Normal function usage - use the uppercase metrics
    HTTP_REQUESTS_TOTAL.labels(
        service="orchestrator",  # Default service name
        method=method,
        endpoint=endpoint,
        status_code=str(status),
    ).inc()
    HTTP_REQUEST_DURATION.labels(
        service="orchestrator", method=method, endpoint=endpoint
    ).observe(duration)


def maybe_start_metrics_server(port: int = 9090) -> None:
    """Start metrics server if not already running."""
    try:
        start_http_server(port)
    except OSError:
        # Server already running
        pass


def record_post_generation(persona_id: str, status: str, cost: float = 0.0) -> None:
    """Record post generation metrics."""
    POSTS_GENERATED_TOTAL.labels(persona_id=persona_id, status=status).inc()
    if cost > 0:
        COST_PER_POST.labels(persona_id=persona_id).set(cost)


def update_service_uptime(service_name: str, uptime_seconds: float) -> None:
    """Update service uptime metric."""
    # We don't have a specific uptime metric, but we can use health status
    SYSTEM_HEALTH_STATUS.labels(component="api", service=service_name).set(1)


def update_system_health(component: str, service: str, healthy: bool) -> None:
    """Update system health status."""
    SYSTEM_HEALTH_STATUS.labels(component=component, service=service).set(
        1 if healthy else 0
    )


# ───── Legacy Functions for Backward Compatibility ──────────────────────────────────────
def record_celery_task(task_name: str, status: str, duration: float = 0.0) -> None:
    """Record Celery task execution metrics."""
    # Map to infrastructure metrics
    record_infrastructure_metric(
        "task_execution",
        component="celery",
        operation=task_name,
        status=status,
        duration=duration,
    )


def record_error(service: str, error_type: str, error_message: str = "") -> None:
    """Record error occurrences."""
    # Map to infrastructure metrics
    record_infrastructure_metric(
        "service_errors", component=service, service=service, error_type=error_type
    )


def record_database_query(operation: str, table: str, duration: float) -> None:
    """Record database query metrics."""
    # Map to infrastructure metrics
    record_infrastructure_metric(
        "database_queries",
        component="postgres",
        operation=f"{operation}_{table}",
        duration=duration,
    )


def record_qdrant_operation(operation: str, collection: str, duration: float) -> None:
    """Record Qdrant vector database operations."""
    # Map to infrastructure metrics
    record_infrastructure_metric(
        "vector_operations",
        component="qdrant",
        operation=f"{operation}_{collection}",
        duration=duration,
    )


def update_cost_per_post(persona_id: str, cost: float) -> None:
    """Update the cost per post metric."""
    # Map to finops metrics
    record_finops_metric(
        "cost_tracking", resource="post_generation", cost_type=persona_id, amount=cost
    )


def record_hourly_openai_cost(model: str, cost: float) -> None:
    """Record hourly OpenAI API costs."""
    # Map to finops metrics
    record_finops_metric("api_costs", resource="openai", cost_type=model, amount=cost)


def record_openai_cost(model: str, cost: float) -> None:
    """Record OpenAI API cost."""
    # Record to the total counter
    OPENAI_API_COSTS_TOTAL.labels(model=model).inc(cost)
    # Map to finops metrics
    record_finops_metric("api_costs", resource="openai", cost_type=model, amount=cost)


def record_cost_per_follow(persona_id: str, cost: float) -> None:
    """Record cost per follower metric."""
    # COST_PER_FOLLOW is a Histogram, so use observe instead of set
    COST_PER_FOLLOW.labels(persona_id=persona_id).observe(cost)


def record_error_rate_percentage(service: str, error_type: str, rate: float) -> None:
    """Record error rate percentage for a service."""
    # This can be calculated from error counts vs total requests
    # For now, we will just record it as a gauge using the ERROR_RATE_BY_SERVICE metric
    ERROR_RATE_BY_SERVICE.labels(
        service=service, error_type=error_type, severity="warning"
    ).inc(
        int(rate)
    )  # Convert rate to count for counter metric


def update_content_quality(persona_id: str, content_type: str, score: float) -> None:
    """Update content quality score."""
    CONTENT_QUALITY_SCORE.labels(persona_id=persona_id, content_type=content_type).set(
        score
    )


@contextmanager
def record_http_request_context(
    service: str, method: str, endpoint: str
) -> Generator[None, None, None]:
    """Context manager for recording HTTP request metrics."""
    start_time = time.time()
    try:
        yield
        # Success
        duration = time.time() - start_time
        HTTP_REQUESTS_TOTAL.labels(
            service=service, method=method, endpoint=endpoint, status_code="200"
        ).inc()
        HTTP_REQUEST_DURATION.labels(
            service=service, method=method, endpoint=endpoint
        ).observe(duration)
    except Exception:
        # Error
        duration = time.time() - start_time
        HTTP_REQUESTS_TOTAL.labels(
            service=service, method=method, endpoint=endpoint, status_code="500"
        ).inc()
        HTTP_REQUEST_DURATION.labels(
            service=service, method=method, endpoint=endpoint
        ).observe(duration)
        raise


@contextmanager
def record_business_metric_context(metric_type: str) -> Generator[None, None, None]:
    """Context manager for recording business metrics."""
    # Could add timing or other metrics here in the future
    try:
        yield
        # Success - you would record appropriate metrics here
    except Exception:
        # Error - record failure
        raise

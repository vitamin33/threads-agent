# /services/common/metrics.py
"""Common Prometheus metrics helpers (CRA-212 + CRA-216 enhancements)."""

from __future__ import annotations

import time
from contextlib import contextmanager
from typing import Generator, Literal

from prometheus_client import Counter, Gauge, Histogram, Summary, start_http_server

# ───── Core Pipeline Metrics (CRA-212) ──────────────────────────────────────────────────
REQUEST_LATENCY = Summary(
    "request_latency_seconds",
    "End-to-end request (phase) latency",
    ["phase"],  # e.g. parse, llm, persist
)

LLM_TOKENS_TOTAL = Counter(
    "llm_tokens_total",
    "Total LLM tokens - labelled by model",
    ["model"],
)

# ───── Business Metrics (CRA-216) ────────────────────────────────────────────────────
POSTS_GENERATED_TOTAL = Counter(
    "posts_generated_total",
    "Total posts generated by persona and status",
    ["persona_id", "status"],  # status: success, failed, blocked
)

CONTENT_GENERATION_LATENCY = Histogram(
    "content_generation_latency_seconds",
    "Complete content generation pipeline latency",
    ["persona_id", "phase"],  # phase: hook, body, total
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
)

ENGAGEMENT_RATE_PREDICTION = Gauge(
    "engagement_rate_prediction",
    "Predicted engagement rate for generated content",
    ["persona_id"],
)

CONTENT_QUALITY_SCORE = Gauge(
    "content_quality_score",
    "Quality score of generated content (0-1)",
    ["persona_id", "content_type"],  # content_type: hook, body, combined
)

# ───── API Metrics (RED Methodology) ─────────────────────────────────────────────────
HTTP_REQUESTS_TOTAL = Counter(
    "http_requests_total",
    "Total HTTP requests by service, method, endpoint and status",
    ["service", "method", "endpoint", "status_code"],
)

HTTP_REQUEST_DURATION = Histogram(
    "http_request_duration_seconds",
    "HTTP request latency by service, method and endpoint",
    ["service", "method", "endpoint"],
    buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
)

HTTP_REQUESTS_IN_FLIGHT = Gauge(
    "http_requests_in_flight",
    "Current number of HTTP requests being processed",
    ["service", "endpoint"],
)

# ───── Infrastructure Metrics (USE Methodology) ──────────────────────────────────────
CELERY_TASKS_TOTAL = Counter(
    "celery_tasks_total",
    "Total Celery tasks by name and status",
    ["task_name", "status"],  # status: success, failure, retry
)

CELERY_TASK_DURATION = Histogram(
    "celery_task_duration_seconds",
    "Celery task execution time",
    ["task_name"],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0],
)

CELERY_QUEUE_LENGTH = Gauge(
    "celery_queue_length", "Number of tasks waiting in Celery queue", ["queue_name"]
)

DATABASE_CONNECTIONS_ACTIVE = Gauge(
    "database_connections_active",
    "Active database connections",
    ["database", "service"],
)

DATABASE_QUERY_DURATION = Histogram(
    "database_query_duration_seconds",
    "Database query execution time",
    ["database", "operation"],  # operation: select, insert, update, delete
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0],
)

# ───── Vector Database Metrics ───────────────────────────────────────────────────────
QDRANT_OPERATIONS_TOTAL = Counter(
    "qdrant_operations_total",
    "Total Qdrant operations by type and status",
    ["operation", "collection", "status"],  # operation: upsert, search, delete
)

QDRANT_OPERATION_DURATION = Histogram(
    "qdrant_operation_duration_seconds",
    "Qdrant operation execution time",
    ["operation", "collection"],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0, 5.0],
)

QDRANT_COLLECTION_SIZE = Gauge(
    "qdrant_collection_size", "Number of vectors in Qdrant collection", ["collection"]
)

# ───── Cost Tracking Metrics ─────────────────────────────────────────────────────────
OPENAI_API_COSTS = Counter(
    "openai_api_costs_usd_total",
    "Total OpenAI API costs in USD",
    ["model", "operation"],  # operation: completion, embedding, moderation
)

COST_PER_POST = Gauge(
    "cost_per_post_usd", "Cost in USD to generate each post", ["persona_id"]
)

# ───── Performance & Reliability ─────────────────────────────────────────────────────
CACHE_OPERATIONS_TOTAL = Counter(
    "cache_operations_total",
    "Total cache operations",
    [
        "cache_type",
        "operation",
        "result",
    ],  # operation: get, set, delete; result: hit, miss
)

ERROR_RATE_BY_SERVICE = Counter(
    "error_rate_by_service_total",
    "Error count by service and error type",
    ["service", "error_type", "severity"],  # severity: warning, error, critical
)

SYSTEM_HEALTH_STATUS = Gauge(
    "system_health_status",
    "System component health status (1=healthy, 0=unhealthy)",
    ["component", "service"],  # component: database, queue, api, llm
)


# ───── utilities ────────────────────────────────────────────────────────
@contextmanager
def record_latency(
    phase: Literal["parse", "llm", "persist"],
) -> Generator[None, None, None]:
    """Context manager → records time spent inside the **with** block."""
    start = time.perf_counter()
    try:
        yield
    finally:
        REQUEST_LATENCY.labels(phase=phase).observe(time.perf_counter() - start)


@contextmanager
def record_content_generation_latency(
    persona_id: str, phase: Literal["hook", "body", "total"]
) -> Generator[None, None, None]:
    """Context manager for tracking content generation pipeline latency."""
    start = time.perf_counter()
    try:
        yield
    finally:
        duration = time.perf_counter() - start
        CONTENT_GENERATION_LATENCY.labels(persona_id=persona_id, phase=phase).observe(
            duration
        )


@contextmanager
def record_http_request(
    service: str, method: str, endpoint: str
) -> Generator[None, None, None]:
    """Context manager for tracking HTTP request metrics (RED methodology)."""
    start = time.perf_counter()
    HTTP_REQUESTS_IN_FLIGHT.labels(service=service, endpoint=endpoint).inc()

    try:
        yield
        # Default to success if no exception
        status_code = "200"
    except Exception as e:
        # Categorize exceptions to status codes
        status_code = "500"  # Default to server error
        if hasattr(e, "status_code"):
            status_code = str(e.status_code)
        raise
    finally:
        duration = time.perf_counter() - start
        HTTP_REQUESTS_IN_FLIGHT.labels(service=service, endpoint=endpoint).dec()
        HTTP_REQUESTS_TOTAL.labels(
            service=service, method=method, endpoint=endpoint, status_code=status_code
        ).inc()
        HTTP_REQUEST_DURATION.labels(
            service=service, method=method, endpoint=endpoint
        ).observe(duration)


@contextmanager
def record_celery_task(task_name: str) -> Generator[None, None, None]:
    """Context manager for tracking Celery task execution."""
    start = time.perf_counter()
    status = "success"

    try:
        yield
    except Exception:
        status = "failure"
        raise
    finally:
        duration = time.perf_counter() - start
        CELERY_TASKS_TOTAL.labels(task_name=task_name, status=status).inc()
        CELERY_TASK_DURATION.labels(task_name=task_name).observe(duration)


@contextmanager
def record_database_query(
    database: str, operation: Literal["select", "insert", "update", "delete"]
) -> Generator[None, None, None]:
    """Context manager for tracking database query performance."""
    start = time.perf_counter()
    try:
        yield
    finally:
        duration = time.perf_counter() - start
        DATABASE_QUERY_DURATION.labels(database=database, operation=operation).observe(
            duration
        )


@contextmanager
def record_qdrant_operation(
    operation: Literal["upsert", "search", "delete"], collection: str
) -> Generator[None, None, None]:
    """Context manager for tracking Qdrant vector database operations."""
    start = time.perf_counter()
    status = "success"

    try:
        yield
    except Exception:
        status = "failure"
        raise
    finally:
        duration = time.perf_counter() - start
        QDRANT_OPERATIONS_TOTAL.labels(
            operation=operation, collection=collection, status=status
        ).inc()
        QDRANT_OPERATION_DURATION.labels(
            operation=operation, collection=collection
        ).observe(duration)


def record_post_generation(
    persona_id: str, status: Literal["success", "failed", "blocked"]
) -> None:
    """Record post generation outcome."""
    POSTS_GENERATED_TOTAL.labels(persona_id=persona_id, status=status).inc()


def update_engagement_prediction(persona_id: str, prediction: float) -> None:
    """Update engagement rate prediction gauge."""
    ENGAGEMENT_RATE_PREDICTION.labels(persona_id=persona_id).set(prediction)


def update_content_quality(
    persona_id: str,
    content_type: Literal["hook", "body", "combined"],
    quality_score: float,
) -> None:
    """Update content quality score gauge."""
    CONTENT_QUALITY_SCORE.labels(persona_id=persona_id, content_type=content_type).set(
        quality_score
    )


def record_openai_cost(model: str, operation: str, cost_usd: float) -> None:
    """Record OpenAI API cost."""
    OPENAI_API_COSTS.labels(model=model, operation=operation).inc(cost_usd)


def update_cost_per_post(persona_id: str, cost_usd: float) -> None:
    """Update cost per post gauge."""
    COST_PER_POST.labels(persona_id=persona_id).set(cost_usd)


def record_cache_operation(
    cache_type: str,
    operation: Literal["get", "set", "delete"],
    result: Literal["hit", "miss", "success", "failure"],
) -> None:
    """Record cache operation result."""
    CACHE_OPERATIONS_TOTAL.labels(
        cache_type=cache_type, operation=operation, result=result
    ).inc()


def record_error(
    service: str, error_type: str, severity: Literal["warning", "error", "critical"]
) -> None:
    """Record service error."""
    ERROR_RATE_BY_SERVICE.labels(
        service=service, error_type=error_type, severity=severity
    ).inc()


def update_system_health(component: str, service: str, healthy: bool) -> None:
    """Update system component health status."""
    SYSTEM_HEALTH_STATUS.labels(component=component, service=service).set(
        1 if healthy else 0
    )


def maybe_start_metrics_server(port: int = 9090) -> None:
    """
    Idempotently start the Prometheus exposition HTTP server.

    • Keeps a module-level flag so we don't start multiple times
    • Call this once from service startup (orchestrator, worker, …)
    """
    if getattr(maybe_start_metrics_server, "_started", False):
        return
    start_http_server(port)  # non-blocking
    setattr(maybe_start_metrics_server, "_started", True)

#!/bin/bash
# Smoke Test - Modern Models Evaluation Pipeline
# Tests modern 7B instruction models on LinkedIn content generation
set -e

echo "ğŸš€ MODERN MODELS SMOKE TEST - LINKEDIN EVALUATION"
echo "=================================================="
echo ""

# Step 1: Prepare environment
echo "ğŸ“‹ Step 1: Preparing evaluation environment..."
python -m evalsuite.cli prepare

echo ""
echo "ğŸƒâ€â™‚ï¸ Step 2: Running model evaluations..."
echo ""

# Step 2: Run evaluations on both stacks
echo "   ğŸ”¬ Testing MLX stack..."
python -m evalsuite.cli run --stack mlx --models modern --tasks linkedin_smoke

echo ""
echo "   ğŸ”¬ Testing llama.cpp stack..."  
python -m evalsuite.cli run --stack llamacpp --models modern --tasks linkedin_smoke

echo ""
echo "âš–ï¸  Step 3: Running pairwise judging..."
python -m evalsuite.cli judge --models modern --tasks linkedin_smoke --seeds 3 --allow_ties

echo ""
echo "ğŸ† Step 4: Calculating Elo rankings with bootstrap CIs..."
python -m evalsuite.cli rank --out report/leaderboard.json

echo ""
echo "âš¡ Step 5: Performance benchmarking..."
echo "   ğŸ“Š MLX performance..."
python -m evalsuite.cli perf --stack mlx

echo "   ğŸ“Š llama.cpp performance..."
python -m evalsuite.cli perf --stack llamacpp

echo ""
echo "ğŸ’° Step 6: Cost analysis..."
python -m evalsuite.cli cost

echo ""
echo "ğŸ“„ Step 7: Generating final report..."
python -m evalsuite.cli report

echo ""
echo "âœ… SMOKE TEST COMPLETE!"
echo ""
echo "ğŸ“Š Results:"
echo "   â€¢ Leaderboard: report/leaderboard.json"
echo "   â€¢ Full Report: report/report.md"
echo "   â€¢ MLflow UI: mlflow ui --backend-store-uri file:./mlruns"
echo ""
echo "ğŸ¯ Modern models evaluated:"
echo "   â€¢ Qwen 2.5 7B Instruct"
echo "   â€¢ Mistral 7B Instruct v0.3"  
echo "   â€¢ Phi-3.5 Mini Instruct"
echo "   â€¢ OLMo 7B Instruct"
echo "   â€¢ Yi-1.5 6B Chat"
echo "   â€¢ OPT-2.7B (legacy baseline)"
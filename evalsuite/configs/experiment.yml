# Apple Silicon Local LM Evaluation Configuration
dataset_dir: evalsuite/data/prompts
output_dir: outputs
stacks: ["mlx", "llamacpp", "mps"]

models:
  - id: qwen2.5-7b-instruct
    hf_model: Qwen/Qwen2.5-7B-Instruct
    stack: mps
    license: apache-2.0
    gated: false
    
  - id: mistral-7b-instruct-v0.3
    hf_model: mistralai/Mistral-7B-Instruct-v0.3
    stack: mps
    license: apache-2.0
    gated: false
    
  - id: phi-3.5-instruct
    hf_model: microsoft/Phi-3.5-mini-instruct
    stack: mps
    license: mit
    gated: false
    
  - id: opt-2.7b
    hf_model: facebook/opt-2.7b
    stack: mps
    license: mit
    gated: false

sampling:
  temperature: 0.2
  top_p: 0.9
  max_new_tokens: [128, 384]

seeds: [17, 23, 42]

power:
  kwh_rate: 0.15
  m4_max_tdp: 35

cloud_baseline:
  name: small-instruct
  price_per_1k_output_tokens: 0.15

mlflow:
  tracking_uri: file:./mlruns
  experiment: apple_silicon_local_lm_v2

performance:
  warmup_runs: 5
  timed_runs: 20
  memory_monitoring: true
  
judge:
  provider: openai
  model: gpt-4o-mini
  max_retries: 3
  timeout_seconds: 30
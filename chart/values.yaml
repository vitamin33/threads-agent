# /chart/values.yaml
nameOverride: ""
fullnameOverride: ""

# ───────── core service images ─────────
image:
  repository: ghcr.io/threads-agent-stack/orchestrator
  tag: "0.2.0"

personaRuntime:
  image:
    repository: ghcr.io/threads-agent-stack/persona-runtime
    tag: "0.3.0"
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  env:
    - name: MLFLOW_CLIENT_POOL_SIZE
      value: "5"
    - name: MLFLOW_CACHE_ENABLED
      value: "true"

# RabbitMQ broker DSN used by orchestrator / Celery
rabbitmq:
  url: "amqp://user:pass@rabbitmq:5672/%2f"

# ───────── new stub-stack toggles (all OFF by default) ─────────
postgres:
  enabled: false                   # turn ON in dev/ci values
  storage: 1Gi                     # PVC size; template uses .Values.postgres.storage
  auth:
    postgresPassword: "postgres"   # override in production
    database: "threads"

minio:
  enabled: false                   # turn ON in dev values
  accessKey: "minio"               # overridden in env Secret
  secretKey: "minio123"
  storage: 1Gi

fakeThreads:
  enabled: false                   # turn ON in dev/ci values
  image:
    repository: ghcr.io/threads-agent-stack/fake-threads
    tag: "0.1.0"
  port: 9009

# ───────── RAG Pipeline Service ─────────
ragPipeline:
  enabled: true
  replicaCount: 3
  image:
    repository: ghcr.io/threads-agent-stack/rag-pipeline
    tag: "1.0.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8000
  
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 3Gi
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 8
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 80
    customMetrics:
    - type: Pods
      pods:
        metric:
          name: rag_requests_per_second
        target:
          type: AverageValue
          averageValue: "20"
  
  config:
    # RAG Configuration
    topK: 20
    rerankTopK: 10
    minScore: 0.7
    batchSize: 50
    cacheTTL: 1800
    
    # Connection Pools
    qdrantPoolSize: 20
    redisPoolSize: 15
    embeddingBatchSize: 100
    maxConcurrentBatches: 3
    
    # FastAPI/Uvicorn
    uvicornWorkers: 1
    uvicornBacklog: 2048
  
  serviceMonitor:
    enabled: true
  
  pdb:
    enabled: true
    minAvailable: 2
  pullSecret: ""                   # leave blank unless you push to a private registry

threadsService:                    # orchestrator ↔︎ fake-threads alias
  name: fake-threads
  port: 9009

celeryWorker:
  enabled: true
  image:
    repository: ghcr.io/threads-agent-stack/celery-worker
    tag: "0.2.0"

viralEngine:
  enabled: false                   # turn ON in dev/ci values
  image:
    repository: ghcr.io/threads-agent-stack/viral-engine
    tag: "0.1.0"

viralPatternEngine:
  enabled: false                   # turn ON in dev/ci values
  image:
    repository: ghcr.io/threads-agent-stack/viral-pattern-engine
    tag: "0.1.0"
  models:
    bert:
      enabled: true
      model: "j-hartmann/emotion-english-distilroberta-base"
      batchSize: 8
    vader:
      enabled: true
  cache:
    size: 1000
  database:
    poolSize: 10
    maxOverflow: 20
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilization: 70
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  networkPolicy:
    enabled: false
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "1Gi"
      cpu: "1000m"

threadsAdaptor:
  enabled: false                   # turn ON when using real Threads API
  image:
    repository: threads-adaptor
    tag: "local"
    pullPolicy: IfNotPresent
  replicas: 1
  rateLimit: 20                    # requests per minute
  credentials:
    appId: ""                      # Threads App ID
    appSecret: ""                  # Threads App Secret

revenue:
  enabled: false                   # turn ON to enable revenue infrastructure
  image:
    repository: revenue
    tag: "local"
    pullPolicy: IfNotPresent
  replicas: 1
  stripe:
    apiKey: ""                     # Stripe API key (sk_test_... or sk_live_...)
    webhookSecret: ""              # Stripe webhook endpoint secret
    priceBasic: ""                 # Stripe price ID for basic tier
    pricePro: ""                   # Stripe price ID for pro tier
    priceEnterprise: ""            # Stripe price ID for enterprise tier
  affiliateId: "viral123"          # Default affiliate tracking ID
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

finopsEngine:
  enabled: false                   # turn ON to enable FinOps monitoring
  image:
    repository: finops-engine
    tag: "local"
    pullPolicy: IfNotPresent
  replicas: 1
  service:
    type: ClusterIP
    port: 8095
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  # Alert webhook configuration
  alertWebhooks:
    slack: ""                      # Slack webhook URL
    discord: ""                    # Discord webhook URL
    telegramBotToken: ""          # Telegram bot token
    telegramChatId: ""            # Telegram chat ID
    customWebhook: ""             # Custom webhook URL

techDocGenerator:
  enabled: false                   # turn ON to enable AI Job automation features
  replicaCount: 1
  image:
    repository: ghcr.io/threads-agent-stack/tech-doc-generator
    tag: "0.1.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8080
  
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  
  logLevel: "INFO"
  
  # AI ROI Calculator - Public facing tool for lead generation
  roiCalculator:
    enabled: true
    ingress:
      enabled: false               # turn ON for public access
      host: "ai-roi-calculator.yourdomain.com"
      className: "nginx"
      tlsIssuer: "letsencrypt-prod"
  
  # Lead capture and consultation booking
  leadCapture:
    enabled: true
    email: "vitaliiserbyn@gmail.com"
    linkedin: "https://linkedin.com/in/vitaliiserbyn"
    responseTime: "within 24 hours"
  
  # Content Scheduler - Automated weekly content generation
  contentScheduler:
    enabled: true
    defaultCompanies: "anthropic,notion,stripe,openai,meta"
    platforms: "linkedin,medium,devto"
    autoGenerate: true
    qualityThreshold: 0.7
  
  # Professional Content Engine
  professionalContentEngine:
    enabled: true
    viralEngineIntegration: true
    companyTargeting: true
    qualityGate: true
  
  # Achievement Integration
  achievementIntegration:
    enabled: true
    realDataOnly: true
    portfolioReady: true
  
  # Network policies for security
  networkPolicy:
    enabled: false                 # turn ON for production security
  
  # Pod disruption budget for availability
  podDisruptionBudget:
    enabled: false                 # turn ON for production
    minAvailable: 1
  
  # Horizontal Pod Autoscaler
  hpa:
    enabled: false                 # turn ON for production scaling
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilization: 70
    targetMemoryUtilization: 80

threadsAdaptor:
  credentials:
    accessToken: ""                # Threads Access Token
    userId: ""                     # Threads User ID
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  extraEnv: []

# RAG Pipeline Configuration
ragPipeline:
  enabled: false                   # turn ON in dev/prod values
  replicaCount: 3
  image:
    repository: ghcr.io/threads-agent-stack/rag-pipeline
    tag: "1.0.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8000
  
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 3Gi
  
  config:
    # Performance tuning
    topK: 20
    rerankTopK: 10
    minScore: 0.7
    batchSize: 50
    cacheTTL: 1800
    
    # Connection pools
    qdrantPoolSize: 20
    redisPoolSize: 15
    embeddingBatchSize: 100
    maxConcurrentBatches: 3
    
    # FastAPI/Uvicorn optimization
    uvicornWorkers: 1
    uvicornBacklog: 2048
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 8
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
    customMetrics: []
  
  serviceMonitor:
    enabled: false                 # requires Prometheus CRDs
  
  pdb:
    enabled: true
    minAvailable: 2

# MLflow Performance Optimization Configuration
mlflow:
  trackingUri: "http://mlflow:5000"
  registryUri: "http://mlflow:5000"
  performanceOptimization:
    enabled: true
    
    # Connection Pool Settings
    clientPoolSize: 10
    maxIdleTime: 600               # seconds
    cleanupInterval: 300           # seconds
    
    # Cache Configuration
    cacheEnabled: true
    cacheTtl: 300                  # seconds
    cacheMaxSize: 128              # number of cached items
    
    # Batch Operation Settings
    batchSize: 50
    batchTimeout: 30               # seconds
    
    # Thread Pool Configuration
    threadPoolSize: 4
    
    # Memory Management
    memoryLimitMb: 512
    gcInterval: 60                 # seconds
    
    # Performance Monitoring
    monitoring:
      enabled: true
      prometheus: true
      serviceMonitor:
        enabled: true
        interval: "30s"
        scrapeTimeout: "10s"
    
    # Auto-scaling Configuration
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 10
      targetCPU: 70
      targetMemory: 80
      customMetrics:
        enabled: true
        targetOpsPerSecond: "100"
      scaleUp:
        stabilizationWindowSeconds: 60
        percentPolicy: 100
        periodSeconds: 15
      scaleDown:
        stabilizationWindowSeconds: 300
        percentPolicy: 50
        periodSeconds: 60

# Enhanced resource limits for services using MLflow
orchestrator:
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  env:
    - name: MLFLOW_CLIENT_POOL_SIZE
      value: "10"
    - name: MLFLOW_CACHE_ENABLED
      value: "true"
    - name: MLFLOW_PERFORMANCE_MONITORING_ENABLED
      value: "true"
  
  # Comment Monitoring Pipeline Configuration (CRA-235)
  commentMonitoring:
    enabled: false                    # turn ON in dev/prod values
    
    # Performance Configuration
    batchSize: 10                     # Comments processed per batch
    dedupCacheTTL: 3600              # Deduplication cache TTL in seconds
    processingTimeout: 30             # Processing timeout in seconds
    maxRetries: 3                     # Maximum retry attempts
    backoffMultiplier: 2              # Exponential backoff multiplier
    rateLimitPerMinute: 100          # Rate limit for comment processing
    
    # Monitoring and Metrics
    metrics:
      enabled: true                   # Enable comment monitoring metrics
      customMetrics: ["comment_processing_queue_length", "comment_processing_duration_seconds", "comment_duplicates_detected_total"]
    
    # Alert Thresholds
    alerts:
      queueBacklogThreshold: 500      # Alert when queue length exceeds this
      memoryThresholdGb: 0.8         # Memory usage alert threshold in GB
      cpuThreshold: 0.8              # CPU usage alert threshold (0-1)
      
    # Network Security
    networkPolicy:
      enabled: false                  # turn ON for production security
      
    # RBAC Configuration
    rbac:
      enabled: false                  # turn ON for production
  
  # Service Monitor for Prometheus
  serviceMonitor:
    enabled: false                    # turn ON when Prometheus is enabled
    interval: "30s"
    scrapeTimeout: "10s"
  
  # Horizontal Pod Autoscaler
  autoscaling:
    enabled: false                    # turn ON for production scaling
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilization: 70
    targetMemoryUtilization: 80
    
    # Custom Metrics Scaling
    customMetrics:
      enabled: false                  # turn ON for comment queue-based scaling
      targetQueueLength: 50           # Target comment processing queue length
      
    # Scaling Behavior
    scaleUp:
      stabilizationWindowSeconds: 60
      percentPolicy: 100
      periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      percentPolicy: 50
      periodSeconds: 60
  
  # Pod Disruption Budget
  pdb:
    enabled: false                    # turn ON for production
    minAvailable: 1

# ───────── generic chart knobs ─────────
replicaCount: 1

service:
  type: ClusterIP
  port: 8080

resources: {}

# ───────── monitoring & observability ─────────
monitoring:
  prometheus:
    enabled: false                    # turn ON in dev/prod values
    url: http://prometheus:9090
    image:
      repository: prom/prometheus
      tag: "v2.47.0"
    persistence:
      enabled: false
      size: 2Gi
      storageClass: ""
    resources:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
  grafana:
    enabled: false                     # turn ON in dev/prod values
    image:
      repository: grafana/grafana
      tag: "10.2.0"
    adminPassword: admin123           # override in prod
    plugins: ""                       # comma-separated list of plugins
    persistence:
      enabled: false
      size: 1Gi
      storageClass: ""
    resources:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
  alertmanager:
    enabled: false                        # turn ON in dev/prod values
    image:
      repository: prom/alertmanager
      tag: "v0.26.0"
    replicas: 1
    externalUrl: ""                       # override in prod (e.g., https://alerts.company.com)
    logLevel: info
    dataRetention: 120h
    persistence:
      enabled: false
      size: 1Gi
      storageClass: ""
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 64Mi
    # Email configuration
    smtp:
      smarthost: "localhost:587"
      from: "alerts@threads-agent.com"
      auth:
        username: ""                      # override in prod
        password: ""                      # override in prod
    # PagerDuty integration
    pagerduty:
      enabled: false                      # turn ON in prod values
      integrationKey: ""                  # override in prod (secret)
    # Slack integration
    slack:
      enabled: false                      # turn ON in dev/prod values
      apiUrl: ""                          # override with webhook URL
      warningsChannel: "#alerts-warnings"
      infrastructureChannel: "#alerts-infrastructure"
    # Email recipients
    email:
      enabled: false                      # turn ON in prod values
      from: "alerts@threads-agent.com"
      businessRecipients: "business@threads-agent.com"
      infrastructureRecipients: "ops@threads-agent.com"

# Redis cache for trend analysis and token optimization
redis:
  enabled: false                          # turn ON in dev/prod values for caching
  image:
    repository: redis
    tag: "7-alpine"
  port: 6379
  persistence:
    enabled: false
    size: 1Gi
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  cluster:
    enabled: false                        # turn ON for Redis cluster mode
    nodes: 3
    replicas: 1

# ───────── CI Monitor (disabled by default) ─────────
ciMonitor:
  enabled: false
  image:
    repository: ci-monitor
    tag: local
    pullPolicy: IfNotPresent
  githubToken: ""
  anthropicApiKey: ""
  monitorInterval: "300"
  autoApprove: "false"
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 256Mi

# ───────── Achievement Collector (disabled by default) ─────────
achievementCollector:
  enabled: false                   # turn ON in dev/prod values
  replicas: 1
  image:
    repository: achievement-collector
    tag: "local"
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi
  storage:
    size: 10Gi
    className: ""                  # Use default storage class
  service:
    type: ClusterIP
    port: 8090
  github:
    webhookSecret: ""             # Set in secrets
    token: ""                     # GitHub PAT for API access
  prometheus:
    scrapeInterval: "24"          # hours between metric scrapes
  sqlite:
    enabled: false                # use PostgreSQL by default
  ingress:
    enabled: false
    host: achievements.example.com
    annotations: {}
    tls: []
  env: []

# ───────── Performance Monitor (disabled by default) ─────────
performanceMonitor:
  enabled: false                   # turn ON in dev/prod values
  replicas: 1
  image:
    repository: performance-monitor
    tag: "local"
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 300m
      memory: 384Mi
    requests:
      cpu: 100m
      memory: 256Mi
  logLevel: "INFO"
  # Early kill configuration
  killThreshold: 0.5               # Kill if engagement < 50% of expected
  minInteractions: 10              # Minimum interactions before evaluation
  timeoutMinutes: 10               # Maximum monitoring duration
  checkIntervalSeconds: 30         # How often to check performance
  service:
    type: ClusterIP
    httpPort: 8085
    metricsPort: 9095

# ───────── Viral Metrics Collection (E6) ─────────
viralMetrics:
  enabled: false                   # turn ON in dev/prod values
  replicas: 2
  image:
    repository: viral-metrics
    tag: "local"
    pullPolicy: IfNotPresent
  
  # Performance tuning
  batchSize: 25                    # Posts per batch (optimized from 50)
  maxParallelTasks: 10             # Max concurrent metric calculations
  cacheTtl: 300                    # Redis cache TTL in seconds
  
  # Autoscaling configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    
  # Resource requests/limits optimized for viral metrics workload
  resources:
    requests:
      memory: "256Mi"              # Minimum for efficient processing
      cpu: "100m"                  # Baseline CPU requirement
    limits:
      memory: "1Gi"                # Prevent memory leaks from impacting cluster
      cpu: "500m"                  # Allow burst processing for batch operations
  
  # Service configuration
  service:
    type: ClusterIP
    port: 8080
    metricsPort: 9090

# ───────── CI/CD Pipeline (disabled by default) ─────────
cicdPipeline:
  enabled: false                   # turn ON in dev/prod values
  replicas: 2
  image:
    repository: cicd-pipeline
    tag: "local"
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 500m
      memory: 512Mi
  service:
    type: ClusterIP
    port: 8087
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    customMetrics:
      enabled: false               # turn ON for custom metrics scaling
    scaleUp:
      stabilizationWindowSeconds: 60
      percentPolicy: 100
      periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      percentPolicy: 50
      periodSeconds: 60
  monitoring:
    enabled: false                 # turn ON in dev/prod values
  redis:
    enabled: false                 # turn ON for performance optimization
    host: redis
    port: 6379
  sidecar:
    enabled: false                 # turn ON for sidecar deployment pattern
  github:
    enabled: false                 # turn ON for GitHub integration
    token: ""                      # GitHub personal access token
    webhookSecret: ""              # GitHub webhook secret
  networkPolicy:
    enabled: false                 # turn ON for network segmentation
  podDisruptionBudget:
    enabled: false                 # turn ON for high availability
    minAvailable: 1

# ───────── OpenAI Configuration ─────────
openai:
  enabled: false                   # turn ON when using OpenAI
  apiKey: ""                       # Set via secret or environment variable

# ───────── Qdrant Vector Database ─────────
qdrant:
  enabled: false                   # turn ON for vector search capabilities
  image:
    repository: qdrant/qdrant
    tag: "latest"
  port: 6333
  persistence:
    enabled: false
    size: 2Gi
  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 512Mi

# ───────── Apache Airflow Orchestration (CRA-284) ─────────
airflow:
  enabled: false                   # turn ON for E7 - Viral Learning Flywheel orchestration
  image:
    repository: apache/airflow
    tag: "2.8.0-python3.12"
    pullPolicy: IfNotPresent
  
  # Authentication and Security (REQUIRED in production)
  adminUsername: "admin"           # Admin user name
  adminEmail: "admin@threads-agent.com"  # Admin email
  adminPassword: ""                # REQUIRED - set in production values
  fernetKey: ""                    # REQUIRED - 32 bytes base64 encoded key
  webserverSecretKey: ""           # REQUIRED - unique secret key per deployment
  
  # Core Configuration
  maxActiveRuns: 3                 # Maximum concurrent DAG runs
  parallelism: 32                  # Total task slots across all workers
  maxActiveTasks: 16              # Maximum tasks per DAG run
  schedulerThreads: 2             # Scheduler thread pool size
  defaultTaskRetries: 2           # Default retry count for failed tasks
  sqlAlchemyPoolSize: 10          # Database connection pool size
  sqlAlchemyMaxOverflow: 20       # Max overflow connections
  
  # Webserver Configuration
  webserver:
    replicas: 1
    baseUrl: "http://localhost:8080"  # External base URL
    exposeConfig: "False"           # Don't expose config in production
    authenticate: "True"            # Enable authentication
    authBackend: "airflow.api.auth.backend.basic_auth"  # Auth method
    sessionTimeout: 30              # Session timeout in minutes
    workerTimeout: 120              # Worker timeout in seconds
    resources:
      requests:
        memory: "512Mi"
        cpu: "200m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    # Pod Disruption Budget
    pdb:
      minAvailable: 1
    # Autoscaling
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 5
      targetCPUUtilization: 70
      targetMemoryUtilization: 80
  
  # Scheduler Configuration
  scheduler:
    replicas: 1
    resources:
      requests:
        memory: "512Mi"
        cpu: "200m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    # Pod Disruption Budget
    pdb:
      minAvailable: 1
  
  # Service Configuration
  service:
    type: ClusterIP
    port: 8080
    
  # Network Policy
  networkPolicy:
    enabled: true                   # Enable network isolation
    
  # Metrics Configuration
  metrics:
    statsd:
      enabled: true
      host: "prometheus-statsd-exporter"
      port: 9125
      prefix: "airflow"
    allowList: "airflow.dag_processing.last_runtime.*,airflow.dag_processing.import_errors,airflow.dag.*.*.duration,airflow.dag.*.*.success,airflow.dag.*.*.failure"
    scrapeInterval: "30s"
    scrapeTimeout: "10s"
  
  # DAG Configuration
  dags:
    # Viral Learning Flywheel DAG settings
    viralLearningFlywheel:
      enabled: true
      schedule: "0 */6 * * *"      # Run every 6 hours
      maxActiveRuns: 1
      catchup: false
      
      # Scraping Configuration
      scraping:
        accounts: ["viral_account_1", "viral_account_2", "viral_account_3"]
        maxPostsPerAccount: 50
        daysBack: 7
        minPerformancePercentile: 95.0
        
      # Pattern Extraction Configuration  
      patternExtraction:
        batchSize: 25
        maxParallelTasks: 5
        
      # Content Generation Configuration
      contentGeneration:
        variants: 3
        personas: ["professional", "casual", "technical"]
        
      # Performance Monitoring
      monitoring:
        engagementThreshold: 0.06    # 6% target engagement rate
        costPerFollowThreshold: 0.01 # $0.01 target cost per follow
        
    # Cleanup and Maintenance DAGs
    maintenance:
      enabled: true
      schedule: "0 2 * * *"        # Daily at 2 AM
      retentionDays: 30            # Keep task logs for 30 days
      
  # Integration URLs (auto-configured from service names)
  services:
    orchestrator: "http://orchestrator:8080"
    viralScraper: "http://viral-scraper:8080"
    viralEngine: "http://viral-engine:8080"
    viralPatternEngine: "http://viral-pattern-engine:8080"
    personaRuntime: "http://persona-runtime:8080"
    prometheus: "http://prometheus:9090"
    
  # Backup Strategy
  backup:
    enabled: false                  # Enable database backups
    schedule: "0 3 * * *"           # Daily at 3 AM
    retention: "7d"                 # Keep backups for 7 days
    storage:
      type: "s3"                   # s3, gcs, or local
      bucket: "airflow-backups"
      region: "us-west-2"
      
  # External Secrets (for production)
  externalSecrets:
    enabled: false                  # Use external secret management
    secretStore: "vault"            # vault, aws-secrets-manager, etc.
    
  # Monitoring and Observability
  monitoring:
    enabled: true
    prometheus:
      enabled: true
      scrapeInterval: "30s"
    grafana:
      enabled: true
      dashboardsEnabled: true

# ===== Conversation Engine Service =====
conversationEngine:
  enabled: true
  image:
    repository: conversation-engine
    tag: latest
    pullPolicy: IfNotPresent
  
  replicas: 2
  
  # GPT-4o Configuration
  model: "gpt-4o"
  temperature: "0.7"
  cacheTTL: "3600"  # 1 hour
  
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  
  pdb:
    enabled: false
    minAvailable: 1
  
  serviceMonitor:
    enabled: false
  
  # Extra environment variables
  extraEnv: []
